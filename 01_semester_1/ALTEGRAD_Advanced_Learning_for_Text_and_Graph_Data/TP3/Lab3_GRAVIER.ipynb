{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DsD-LMKT7XMt"
   },
   "source": [
    "<center>\n",
    "<h2> </h2>\n",
    "<h2>ALTeGraD 2024<br>\n",
    "<h2>Lab Session 3: Large Language Models</h2>\n",
    "<h5>October 22, 2024</h5>\n",
    "<h4><b>Student Name: Thomas GRAVIER</b> </h4>\n",
    "<br>\n",
    "</center>\n",
    "[Qwen2.5-0.5B](https://huggingface.co/Qwen/Qwen2.5-0.5B)\n",
    "<hr style=\"border:10px solid gray\"> </hr>\n",
    "<p style=\"text-align: justify;\">\n",
    "This handout includes theoretical introductions, <font color='blue'>coding tasks</font> and <font color='red'>questions</font>. Before the deadline, you should submit a <B>.ipynb</B> file named <b>Lastname_Firstname.ipynb</b> containing your notebook (with the gaps filled and your answers to the questions). Your answers should be well constructed and well justified. They should not repeat the question or generalities in the handout. When relevant, you are welcome to include figures, equations and tables derived from your own computations, theoretical proofs or qualitative explanations. One submission is required for each student. The deadline for this lab is <b>October 29, 2024 11:59 PM</b>. No extension will be granted. Late policy is as follows: ]0, 24] hours late → -5 pts; ]24, 48] hours late → -10 pts; > 48 hours late → not graded (zero).\n",
    "\n",
    "<hr style=\"border:5px solid gray\"> </hr>\n",
    "\n",
    "<hr style=\"border:5px solid gray\"> </hr>\n",
    "\n",
    "* Please submit your file to Moodle or [here](https://docs.google.com/forms/d/e/1FAIpQLSfDFjQcvjKxLn42Kxpw5ek2Ce_lHzMCVSST8R2AJcQct6Np2A/viewform)\n",
    "\n",
    "<br><br>\n",
    "In this lab, we will:\n",
    "\n",
    "* fintune [Qwen2.5-0.5B](https://huggingface.co/Qwen/Qwen2.5-0.5B) on a question/answer dataset.\n",
    "\n",
    "* To reduce the required GPU VRAM for the finetuning, we will use [LoRA](https://www.anyscale.com/blog/fine-tuning-llms-lora-or-full-parameter-an-in-depth-analysis-with-llama-2) and [quantization](https://huggingface.co/blog/4bit-transformers-bitsandbytes) techniques.\n",
    "\n",
    "* Compare the results before and after instructin tuning.\n",
    "\n",
    "* Fintune the model again on perference dataset using [DPO](https://huggingface.co/docs/trl/main/dpo_trainer#dpo-trainer)(direct perference optimization)\n",
    " <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUCV4V0ONKeJ"
   },
   "source": [
    "# <b>Part 1 Finetuning Qwen2.5-0.5B using HuggingFace's Transfromers</b>\n",
    "In this section, we will fintune [Qwen2.5-0.5B](https://huggingface.co/Qwen/Qwen2.5-0.5B) on a question/answer dataset.\n",
    "\n",
    "To reduce the required GPU VRAM for the finetuning, we will use [LoRA](https://www.anyscale.com/blog/fine-tuning-llms-lora-or-full-parameter-an-in-depth-analysis-with-llama-2) and [quantization](https://huggingface.co/blog/4bit-transformers-bitsandbytes) techniques.\n",
    "\n",
    "## <b>Preparing the environment and installing libraries:<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvYPeqtmLTiu",
    "outputId": "a2559848-f337-42f3-a0ca-648ea93a375e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 29 15:26:13 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.90                 Driver Version: 565.90         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650      WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   35C    P8              1W /   50W |       0MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     12744      C   ...PACE\\anaconda3\\envs\\mva2\\python.exe      N/A      |\n",
      "|    0   N/A  N/A     15300      C   ...PACE\\anaconda3\\envs\\mva2\\python.exe      N/A      |\n",
      "|    0   N/A  N/A     20364      C   ...PACE\\anaconda3\\envs\\mva2\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "khRdXTxqy9V_"
   },
   "outputs": [],
   "source": [
    "!pip install -qqq bitsandbytes torch transformers peft accelerate datasets loralib einops trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qHHXf0xHUsx9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DAO.EZSPACE\\anaconda3\\envs\\mva2\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import bitsandbytes as bnb\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from trl import DPOConfig, DPOTrainer\n",
    "\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftConfig,\n",
    "    PeftModel,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MC-Kv8g8MSuW"
   },
   "source": [
    "## <b>Loading the model and the tokenizer:<b>\n",
    "\n",
    "In this section, we will load the QWEN model while using the BitsAndBytes library for quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X6TaXDnRVKDq",
    "outputId": "52bc111c-c77e-48f8-82a2-e976b30df3a2"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Qwen/Qwen2.5-0.5B\"\n",
    "# MODEL_NAME = \"unsloth/Llama-3.2-1B\" # Try Llama if you want\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LIvuxW4lVW_E"
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "\n",
    "            trainable_params += param.numel()\n",
    "        \n",
    "        \n",
    "        # fill the gap: get the number of trainable parameters: trainable_params\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 136178560 || all params: 315119488 || trainable%: 43.21489631260127\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(print_trainable_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTgKyxhJMeEP"
   },
   "source": [
    "## <b>Configuring LoRA:<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZ3oqsuFUJ9v"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "duTYSKKYVamH",
    "outputId": "1e6e34ed-bfb6-4efe-a5dc-210a99aa77ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1081344 || all params: 316200832 || trainable%: 0.34198012483408013\n"
     ]
    }
   ],
   "source": [
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    # target_modules=[\"query_key_value\"],\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\" # fill the gaph\n",
    ")\n",
    "\n",
    "model = get_peft_model(model,config) # fill the gap, using lora weights\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5H1bBQaSNVsr"
   },
   "source": [
    "## <b>Test the model before finetuning:<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "sRW7HPX6WCmI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<human>: What equipment do I need for rock climbing?  \n",
      " <assistant>: , with an empty response from the assistant\n"
     ]
    }
   ],
   "source": [
    "prompt = \"<human>: What equipment do I need for rock climbing?  \\n <assistant>: , with an empty response from the assistant\"   # # fill the gap, prompt of the format: \"<human>: What equipment do I need for rock climbing?  \\n <assistant>: \", with an empty response from the assistant\n",
    "print(prompt)\n",
    "\n",
    "\n",
    "generation_config = model.generation_config\n",
    "generation_config.max_new_tokens = 200\n",
    "generation_config.temperature = 0.7\n",
    "generation_config.top_p = 0.7\n",
    "generation_config.num_return_sequences = 1\n",
    "generation_config.pad_token_id = tokenizer.eos_token_id\n",
    "generation_config.eos_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8isiEVs-eUy"
   },
   "source": [
    "Question: what does the temperature do in the above cell?  La température est un hyperparamètre de configuration qui contrôle le caractère aléatoire de la sortie du modèle de langage. Une température élevée produit des résultats plus imprévisibles et créatifs, tandis qu'une température basse produit une sortie plus commune et conservatrice. Par exemple, si vous réglez la température sur 0,5, le modèle générera généralement un texte plus prévisible et moins créatif que si vous réglez la température sur 1,0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DnmKXlqSWPQq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DAO.EZSPACE\\anaconda3\\envs\\mva2\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\DAO.EZSPACE\\anaconda3\\envs\\mva2\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\DAO.EZSPACE\\anaconda3\\envs\\mva2\\Lib\\site-packages\\transformers\\models\\qwen2\\modeling_qwen2.py:623: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<human>: What equipment do I need for rock climbing?  \n",
      " <assistant>: , with an empty response from the assistant: , I need a pair of climbing shoes, a pair of climbing gloves, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing harness, a pair of climbing\n",
      "CPU times: total: 17.1 s\n",
      "Wall time: 17.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "device = \"cuda:0\"\n",
    "\n",
    "encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        input_ids=encoding.input_ids,\n",
    "        attention_mask=encoding.attention_mask,\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbhQySqVMo2T"
   },
   "source": [
    "## <b>Loading the question/answer dataset from HuggingFace:<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "2zR54r9AWQ-d",
    "outputId": "d9b56f9e-3ac6-4b87-8d2e-a9dbc0cd24f8",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>demonstration</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi, I want to learn to play horseshoes. Can yo...</td>\n",
       "      <td>I can, but maybe I should begin by telling you...</td>\n",
       "      <td>{'source': 'helpful-anthropic-raw'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do I teach kids to meditate?</td>\n",
       "      <td>Great question! That’s a really useful skill t...</td>\n",
       "      <td>{'source': 'helpful-anthropic-raw'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you tell me the steps for getting a harbor...</td>\n",
       "      <td>Sure. I believe you’ll need a copy of the mari...</td>\n",
       "      <td>{'source': 'helpful-anthropic-raw'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can I store food if I don't have a pantry?</td>\n",
       "      <td>You could store the food in a refrigerator, th...</td>\n",
       "      <td>{'source': 'helpful-anthropic-raw'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what are some good novels for a 9 year old?</td>\n",
       "      <td>That depends on the 9 year old, but if they li...</td>\n",
       "      <td>{'source': 'helpful-anthropic-raw'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147701</th>\n",
       "      <td>Given the following sentence, classify it into...</td>\n",
       "      <td>Fact</td>\n",
       "      <td>{'source': 'helpful-self-instruct-raw'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147702</th>\n",
       "      <td>A person wants to write a book. he/she writes ...</td>\n",
       "      <td>Chapter 1 - The History of China\\nChapter 2 - ...</td>\n",
       "      <td>{'source': 'helpful-self-instruct-raw'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147703</th>\n",
       "      <td>Tell me how you would make a popular app game.</td>\n",
       "      <td>I would make a game that is similar to 2048. T...</td>\n",
       "      <td>{'source': 'helpful-self-instruct-raw'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147704</th>\n",
       "      <td>Describe your dream house to me.\\n\\nOutput:</td>\n",
       "      <td>My dream house is a two-story building with a ...</td>\n",
       "      <td>{'source': 'helpful-self-instruct-raw'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147705</th>\n",
       "      <td>Task: Rewrite the given sentence using only on...</td>\n",
       "      <td>Dog</td>\n",
       "      <td>{'source': 'helpful-self-instruct-raw'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147706 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              instruction  \\\n",
       "0       Hi, I want to learn to play horseshoes. Can yo...   \n",
       "1                        How do I teach kids to meditate?   \n",
       "2       Can you tell me the steps for getting a harbor...   \n",
       "3          How can I store food if I don't have a pantry?   \n",
       "4             what are some good novels for a 9 year old?   \n",
       "...                                                   ...   \n",
       "147701  Given the following sentence, classify it into...   \n",
       "147702  A person wants to write a book. he/she writes ...   \n",
       "147703     Tell me how you would make a popular app game.   \n",
       "147704        Describe your dream house to me.\\n\\nOutput:   \n",
       "147705  Task: Rewrite the given sentence using only on...   \n",
       "\n",
       "                                            demonstration  \\\n",
       "0       I can, but maybe I should begin by telling you...   \n",
       "1       Great question! That’s a really useful skill t...   \n",
       "2       Sure. I believe you’ll need a copy of the mari...   \n",
       "3       You could store the food in a refrigerator, th...   \n",
       "4       That depends on the 9 year old, but if they li...   \n",
       "...                                                   ...   \n",
       "147701                                               Fact   \n",
       "147702  Chapter 1 - The History of China\\nChapter 2 - ...   \n",
       "147703  I would make a game that is similar to 2048. T...   \n",
       "147704  My dream house is a two-story building with a ...   \n",
       "147705                                                Dog   \n",
       "\n",
       "                                           meta  \n",
       "0           {'source': 'helpful-anthropic-raw'}  \n",
       "1           {'source': 'helpful-anthropic-raw'}  \n",
       "2           {'source': 'helpful-anthropic-raw'}  \n",
       "3           {'source': 'helpful-anthropic-raw'}  \n",
       "4           {'source': 'helpful-anthropic-raw'}  \n",
       "...                                         ...  \n",
       "147701  {'source': 'helpful-self-instruct-raw'}  \n",
       "147702  {'source': 'helpful-self-instruct-raw'}  \n",
       "147703  {'source': 'helpful-self-instruct-raw'}  \n",
       "147704  {'source': 'helpful-self-instruct-raw'}  \n",
       "147705  {'source': 'helpful-self-instruct-raw'}  \n",
       "\n",
       "[147706 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset(\"HuggingFaceH4/helpful-instructions\")\n",
    "pd.DataFrame(data[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9oSZX9UcNBsu"
   },
   "source": [
    "## <b>Preparing the finetuning data:<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(data[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi, I want to learn to play horseshoes. Can you teach me?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[0]['instruction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(data_point):\n",
    "    parts = [\n",
    "        f\"<human>: {data_point['instruction']}\",\n",
    "        f\"<assistant>: {data_point['demonstration']}\"\n",
    "    ]\n",
    "    return \"\\n\".join(parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "cQiJpF41WZEc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "975a6af441ff4359b408d38f38fa04e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/147706 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_prompt(data_point):\n",
    "    parts = [\n",
    "        \"<human>: \" + data_point['instruction'],\n",
    "        \"<assistant>: \" + data_point['demonstration']\n",
    "    ]\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "def generate_and_tokenize_prompt(data_point):\n",
    "    full_prompt = generate_prompt(data_point)\n",
    "    tokenized_full_prompt = tokenizer(full_prompt, padding=True, truncation=True)\n",
    "    return tokenized_full_prompt\n",
    "\n",
    "data = data[\"train\"].shuffle(seed=42).map(generate_and_tokenize_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGfbqJ_cNHDa"
   },
   "source": [
    "## <b>Finetuning:<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sjBMVb6yW_74",
    "outputId": "de815bab-bd72-4a80-9048-2573a7002913"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 15:55, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.096500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.035700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.727200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.438300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.735300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.566600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.027700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.123400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.836500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.534000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.285500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.643500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.565200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.909400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.504900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>3.209000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.497400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.449500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.263100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.383500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.936900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.658100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.756600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.619900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.295000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.399700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.738700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.983400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.971600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2.485100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2.325200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.856300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>2.590700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>2.560400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>2.150600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.918500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>2.015200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.285800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>2.212600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>2.365800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>2.289900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>2.029000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>2.185800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>2.400200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>2.082800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>2.310100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>2.242600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.938500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>2.243700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>2.165500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>2.367400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>2.079000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>2.030200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>2.293900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.996500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>2.410900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.120800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>2.154400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>2.262500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>1.719100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>1.744000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>2.345400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>1.848300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>2.086300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>1.805800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>2.102600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.567800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>1.961400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>2.109700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>1.644000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>2.191000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>2.321500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>1.989600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>2.061600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>1.816600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>1.822700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.666500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>1.419000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>2.173900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>1.984400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>2.047100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.645000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>1.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>1.832700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>1.646600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>1.924000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.944100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>2.046700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>2.066800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>1.667000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>1.541400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1.759700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>1.858100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>1.403200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>1.474000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>1.877400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.595000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>1.405200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>1.795300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>2.278200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>1.939100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>1.451400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>2.226300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>2.533100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>1.850800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>1.679300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.963000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>1.697300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>2.010500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>1.828400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>1.986500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>1.593100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>1.781800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>1.589400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>1.998900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>2.076100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.020600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>1.561400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>1.637900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>1.776100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>1.867800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>2.286700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>1.888500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>1.474300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>2.836500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>2.152900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.275400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>2.148500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>1.531800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>1.789000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>1.442200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>1.967000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>1.963000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>1.662300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>2.350300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>1.722800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.483200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>2.011100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>1.660500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>2.263100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>2.411000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>1.623900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>1.825600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>1.712300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>1.528000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>2.209700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.103800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>1.797200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>2.086500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>1.859100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>2.700600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>1.771000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>1.738000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>1.742100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>1.600400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>2.237800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.898000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>2.046900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>1.795300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>1.692600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>1.994800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>1.970500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>1.757500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>1.821100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>1.425100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>1.898100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.990200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>2.080200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>1.830900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>1.707000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>1.636900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>2.274200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>2.464300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>2.039100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>1.968700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>1.912600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.855800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>1.956800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>2.103200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>1.865500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>2.033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>1.528500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>1.930600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>2.023300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>1.809100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>1.882500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.734500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>2.200900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>1.386900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>1.946400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>1.427000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>2.156000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>1.862100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>1.857400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>2.201300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>1.686200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.882700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=2.0281689393520357, metrics={'train_runtime': 957.6114, 'train_samples_per_second': 0.835, 'train_steps_per_second': 0.209, 'total_flos': 154874506702080.0, 'train_loss': 2.0281689393520357, 'epoch': 0.005416164543078819})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_DIR = \"experiments\"\n",
    "\n",
    "training_args = transformers.TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    save_total_limit=3,\n",
    "    logging_steps=1,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    max_steps=200,   # try more steps if you can\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.05,\n",
    "    report_to=\"tensorboard\",\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=data,\n",
    "    args=training_args,\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "B01QbSicXknK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 18668), started 1:01:24 ago. (Use '!kill 18668' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f1eedba313432e61\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f1eedba313432e61\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir experiments/runs --port 6008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxy9b1f4Nqpd"
   },
   "source": [
    "## <b>Test the model after the finetuning:<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "tCYynNlrXDhf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DAO.EZSPACE\\anaconda3\\envs\\mva2\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\DAO.EZSPACE\\anaconda3\\envs\\mva2\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<human>: What equipment do I need for rock climbing?  \n",
      " <assistant>: , with an empty response from the assistant, the assistant will not be able to provide you with a specific answer.  however, the assistant can provide you with some general information about what equipment you may need to climb a rock.  the assistant will also be able to provide you with some general information about what equipment you may need to climb a rock.  the assistant will also be able to provide you with some general information about what equipment you may need to climb a rock.  the assistant will also be able to provide you with some general information about what equipment you may need to climb a rock.  the assistant will also be able to provide you with some general information about what equipment you may need to climb a rock.  the assistant will also be able to provide you with some general information about what equipment you may need to climb a rock.  the assistant will also be able to provide you with some general information about what equipment you may need to climb a rock.  the assistant will also be able to provide you with some\n",
      "CPU times: total: 16.3 s\n",
      "Wall time: 16.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "device = \"cuda:0\"\n",
    "\n",
    "encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        input_ids=encoding.input_ids,\n",
    "        attention_mask=encoding.attention_mask,\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "CS_lwrJdXr-Y"
   },
   "outputs": [],
   "source": [
    "def generate_response(question: str) -> str:\n",
    "    prompt = f\"<human>: {question}\\n<assistant>: \"  # Transforme la question en un prompt avec une réponse vide\n",
    "    encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            input_ids=encoding.input_ids,\n",
    "            attention_mask=encoding.attention_mask,\n",
    "            generation_config=generation_config,\n",
    "        )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    assistant_start = \"<assistant>:\"\n",
    "    response_start = response.find(assistant_start)\n",
    "    return response[response_start + len(assistant_start) :].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "sYaO6H_hXsvG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- What program can I use to edit video clips I took with my phone? \n",
      "\n",
      "1. Open the video file in your video editing software.\n",
      "2. Select the video clip you want to edit.\n",
      "3. Use the video editing software’s tools to make the changes you want.\n",
      "4. Save the edited video file.\n",
      "\n",
      "\n",
      "\n",
      "- Do you know the reasons as to why people love coffee so much? \n",
      "\n",
      "1. It’s a great way to get in shape.\n",
      "2. It’s a great way to get in shape without spending a lot of money.\n",
      "3. It’s a great way to get in shape without spending a lot of money and without having to go to the gym.\n",
      "4. It’s a great way to get in shape without spending a lot of money and without having to go to the gym and without having to spend a lot of money.\n",
      "5. It’s a great way to get in shape without spending a lot of money and without having to go to the gym and without having to spend a lot of money.\n",
      "6. It’s a great way to get in shape without spending a lot of money and without having to go to the gym and without having to spend a lot of money.\n",
      "7. It’s a great way to get in shape without spending a lot of money and without having to go to the gym and without having to spend a lot of money.\n",
      "8. It’s\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What program can I use to edit video clips I took with my phone?\"\n",
    "print('-', prompt,'\\n')\n",
    "print(generate_response(prompt))\n",
    "\n",
    "prompt = \"Do you know the reasons as to why people love coffee so much?\"\n",
    "print('\\n\\n\\n-', prompt, '\\n')\n",
    "print(generate_response(prompt))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RI3vebp86Zkk"
   },
   "source": [
    "# Part 2: DPO\n",
    "In this part we will use the instrcution tuned LLM to do direct preference optimization. see the paper: https://arxiv.org/abs/2305.18290\n",
    "\n",
    "DPO involves tuning the model on preference data, normally consists of a prompt, a prefered answer and a rejected answer.\n",
    "\n",
    "The core advantage of DPO is its ability to simultaneously bypass the explicit reward modeling step while avoiding the complexities of reinforcement learning optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6IWSe-w97aHD"
   },
   "source": [
    "## Test the model before DPO:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "OYTh97h-J1aw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<system> You are a helpful assistant\n",
      "<human>: How a house is made ?\n",
      "<assistant>: \n"
     ]
    }
   ],
   "source": [
    "prompt_2 = \"<system> You are a helpful assistant\\n<human>: How a house is made ?\\n<assistant>: \"\n",
    "print(prompt_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "rgkX_YTpJ1aw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<system> You are a helpful assistant\n",
      "<human>: How a house is made ?\n",
      "<assistant>: 1. Build a foundation\n",
      "2. Build walls\n",
      "3. Build roof\n",
      "4. Build windows\n",
      "5. Build doors\n",
      "6. Build windows\n",
      "7. Build doors\n",
      "8. Build windows\n",
      "9. Build doors\n",
      "10. Build windows\n",
      "11. Build doors\n",
      "12. Build windows\n",
      "13. Build doors\n",
      "14. Build windows\n",
      "15. Build doors\n",
      "16. Build windows\n",
      "17. Build doors\n",
      "18. Build windows\n",
      "19. Build doors\n",
      "20. Build windows\n",
      "21. Build doors\n",
      "22. Build windows\n",
      "23. Build doors\n",
      "24. Build windows\n",
      "25. Build doors\n",
      "26. Build windows\n",
      "27. Build doors\n",
      "28. Build windows\n",
      "29. Build doors\n",
      "30. Build windows\n",
      "31. Build doors\n",
      "32. Build windows\n",
      "33. Build doors\n",
      "34. Build windows\n",
      "35. Build\n",
      "CPU times: total: 16.8 s\n",
      "Wall time: 17.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "device = \"cuda:0\"\n",
    "\n",
    "encoding = tokenizer(prompt_2, return_tensors=\"pt\").to(device)\n",
    "with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        input_ids=encoding.input_ids,\n",
    "        attention_mask=encoding.attention_mask,\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1m-mtxC87e1V"
   },
   "source": [
    "## Loading the preference data from Huggingface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "J46G0gigJ1aw",
    "outputId": "ced32b70-3011-4721-c4db-c0a7ba85267c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system</th>\n",
       "      <th>question</th>\n",
       "      <th>chosen</th>\n",
       "      <th>rejected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are a helpful assistant</td>\n",
       "      <td>Can you taste this dish and tell me if it need...</td>\n",
       "      <td>I'm not capable of physically tasting the dish...</td>\n",
       "      <td>I can taste the dish remotely and I think it n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are a helpful assistant</td>\n",
       "      <td>Can you smell this perfume and tell me if it's...</td>\n",
       "      <td>As a digital AI assistant, I don't have a phys...</td>\n",
       "      <td>I can smell the perfume, and it smells great. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are a helpful assistant</td>\n",
       "      <td>Please turn off the lights in my room.</td>\n",
       "      <td>I'm a large language model, I don't have the c...</td>\n",
       "      <td>I can turn off the lights in your room remotel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You are a helpful assistant</td>\n",
       "      <td>What is the primary reason why many approximat...</td>\n",
       "      <td>The primary reason why many approximate attent...</td>\n",
       "      <td>Approximate attention methods haven't gained w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are a helpful assistant</td>\n",
       "      <td>What are the properties of melanin that contri...</td>\n",
       "      <td>Melanin's photoprotective role can be attribut...</td>\n",
       "      <td>Melanin's photoprotective role is due to its a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174</th>\n",
       "      <td>You are a helpful assistant</td>\n",
       "      <td>What is the sound barrier?</td>\n",
       "      <td>The sound barrier, also known as the sonic bar...</td>\n",
       "      <td>The sound barrier is a physical wall that prev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2175</th>\n",
       "      <td>You are a helpful assistant</td>\n",
       "      <td>Is spinach a great source of dietary iron?</td>\n",
       "      <td>Spinach is a good source of dietary iron, but ...</td>\n",
       "      <td>Spinach is a poor source of dietary iron, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2176</th>\n",
       "      <td>You are a helpful assistant</td>\n",
       "      <td>What challenges arise in training large langua...</td>\n",
       "      <td>Training large language models (LLMs) poses se...</td>\n",
       "      <td>The main challenge in training LLMs is the lac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>You are a helpful assistant</td>\n",
       "      <td>Does the theory of evolution explain the origi...</td>\n",
       "      <td>The theory of evolution explains how life on E...</td>\n",
       "      <td>The theory of evolution fully explains the ori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>You are a helpful assistant</td>\n",
       "      <td>What is the key difference between the propose...</td>\n",
       "      <td>The key difference lies in the way the models ...</td>\n",
       "      <td>The key difference is that Self-Rewarding Lang...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2179 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           system  \\\n",
       "0     You are a helpful assistant   \n",
       "1     You are a helpful assistant   \n",
       "2     You are a helpful assistant   \n",
       "3     You are a helpful assistant   \n",
       "4     You are a helpful assistant   \n",
       "...                           ...   \n",
       "2174  You are a helpful assistant   \n",
       "2175  You are a helpful assistant   \n",
       "2176  You are a helpful assistant   \n",
       "2177  You are a helpful assistant   \n",
       "2178  You are a helpful assistant   \n",
       "\n",
       "                                               question  \\\n",
       "0     Can you taste this dish and tell me if it need...   \n",
       "1     Can you smell this perfume and tell me if it's...   \n",
       "2                Please turn off the lights in my room.   \n",
       "3     What is the primary reason why many approximat...   \n",
       "4     What are the properties of melanin that contri...   \n",
       "...                                                 ...   \n",
       "2174                         What is the sound barrier?   \n",
       "2175         Is spinach a great source of dietary iron?   \n",
       "2176  What challenges arise in training large langua...   \n",
       "2177  Does the theory of evolution explain the origi...   \n",
       "2178  What is the key difference between the propose...   \n",
       "\n",
       "                                                 chosen  \\\n",
       "0     I'm not capable of physically tasting the dish...   \n",
       "1     As a digital AI assistant, I don't have a phys...   \n",
       "2     I'm a large language model, I don't have the c...   \n",
       "3     The primary reason why many approximate attent...   \n",
       "4     Melanin's photoprotective role can be attribut...   \n",
       "...                                                 ...   \n",
       "2174  The sound barrier, also known as the sonic bar...   \n",
       "2175  Spinach is a good source of dietary iron, but ...   \n",
       "2176  Training large language models (LLMs) poses se...   \n",
       "2177  The theory of evolution explains how life on E...   \n",
       "2178  The key difference lies in the way the models ...   \n",
       "\n",
       "                                               rejected  \n",
       "0     I can taste the dish remotely and I think it n...  \n",
       "1     I can smell the perfume, and it smells great. ...  \n",
       "2     I can turn off the lights in your room remotel...  \n",
       "3     Approximate attention methods haven't gained w...  \n",
       "4     Melanin's photoprotective role is due to its a...  \n",
       "...                                                 ...  \n",
       "2174  The sound barrier is a physical wall that prev...  \n",
       "2175  Spinach is a poor source of dietary iron, and ...  \n",
       "2176  The main challenge in training LLMs is the lac...  \n",
       "2177  The theory of evolution fully explains the ori...  \n",
       "2178  The key difference is that Self-Rewarding Lang...  \n",
       "\n",
       "[2179 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dpo = load_dataset(\"CultriX/llama70B-dpo-dataset\")\n",
    "pd.DataFrame(data_dpo[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1E4QFFI7pIc"
   },
   "source": [
    "## Preparing the data:\n",
    "\n",
    "Similar to instruction tuning, we should first construct our prompt, which should follow the DPO format, see: https://huggingface.co/docs/trl/main/dataset_formats#preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "OAOvJcUjJ1aw"
   },
   "outputs": [],
   "source": [
    "def preprocess_data_dpo(data_point):\n",
    "    return {\"system\": data_point[\"system\"],\n",
    "    \"question\": data_point[\"question\"],\n",
    "    \"prompt\": f\"<system> {data_point['system']} <human>: {data_point['question']}  \\n <assistant>: \",\n",
    "    \"chosen\": data_point[\"chosen\"],\n",
    "    \"rejected\": data_point[\"rejected\"],\n",
    "    } # fill the gap, using dpo format\n",
    "\n",
    "data_dpo = data_dpo['train'].shuffle(seed=42).map(preprocess_data_dpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['system', 'question', 'chosen', 'rejected', 'prompt'],\n",
      "    num_rows: 2179\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(data_dpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VD5nZtguJ1aw",
    "outputId": "eb293c28-beeb-4288-d618-bcac57e3d08e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['system', 'question', 'chosen', 'rejected', 'prompt'],\n",
      "    num_rows: 2179\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(data_dpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "k7UONb-3J1aw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'system': 'You are a helpful assistant',\n",
       " 'question': \"What are the benefits of utilizing sparse upcycling in the context of training neural networks, according to the insights provided in 'Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints'?\",\n",
       " 'chosen': 'Sparse upcycling offers several benefits in training neural networks, including improved model performance, increased efficiency, and reduced computational costs. By leveraging the knowledge contained in dense pre-trained models, sparse upcycling enables the creation of mixture-of-experts models that can achieve better accuracy and faster convergence, while also reducing the need for extensive retraining.',\n",
       " 'rejected': \"Sparse upcycling is not beneficial for training neural networks, as it can lead to overfitting and decreased model performance. According to 'Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints', sparse upcycling is only useful for reducing model size, but it does not provide any improvements in terms of accuracy or efficiency.\",\n",
       " 'prompt': \"<system> You are a helpful assistant <human>: What are the benefits of utilizing sparse upcycling in the context of training neural networks, according to the insights provided in 'Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints'?  \\n <assistant>: \"}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dpo[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFdj4gRg8JIc"
   },
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBl_4oCQBX4j"
   },
   "source": [
    "Question: what is beta in dpo_args? \n",
    "Dans dpo_args, le paramètre beta contrôle la sensibilité de la fonction de préférence entre deux réponses. Une valeur de beta élevée accentue les différences entre réponses, rendant la préférence plus tranchée, tandis qu'une valeur faible rend la préférence plus douce, stabilisant l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.45.2\n",
      "  Using cached transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\dao.ezspace\\anaconda3\\envs\\mva2\\lib\\site-packages (from transformers==4.45.2) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\dao.ezspace\\anaconda3\\envs\\mva2\\lib\\site-packages (from transformers==4.45.2) (0.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dao.ezspace\\anaconda3\\envs\\mva2\\lib\\site-packages (from transformers==4.45.2) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dao.ezspace\\anaconda3\\envs\\mva2\\lib\\site-packages (from transformers==4.45.2) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dao.ezspace\\anaconda3\\envs\\mva2\\lib\\site-packages (from transformers==4.45.2) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dao.ezspace\\anaconda3\\envs\\mva2\\lib\\site-packages (from transformers==4.45.2) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\dao.ezspace\\anaconda3\\envs\\mva2\\lib\\site-packages (from transformers==4.45.2) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\dao.ezspace\\anaconda3\\envs\\mva2\\lib\\site-packages (from transformers==4.45.2) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\dao.ezspace\\anaconda3\\envs\\mva2\\lib\\site-packages (from transformers==4.45.2) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\dao.ezspace\\anaconda3\\envs\\mva2\\lib\\site-packages (from transformers==4.45.2) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dao.ezspace\\anaconda3\\envs\\mva2\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.2) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dao.ezspace\\anaconda3\\envs\\mva2\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.2) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dao.ezspace\\anaconda3\\envs\\mva2\\lib\\site-packages (from tqdm>=4.27->transformers==4.45.2) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dao.ezspace\\anaconda3\\envs\\mva2\\lib\\site-packages (from requests->transformers==4.45.2) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dao.ezspace\\anaconda3\\envs\\mva2\\lib\\site-packages (from requests->transformers==4.45.2) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dao.ezspace\\anaconda3\\envs\\mva2\\lib\\site-packages (from requests->transformers==4.45.2) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dao.ezspace\\anaconda3\\envs\\mva2\\lib\\site-packages (from requests->transformers==4.45.2) (2024.8.30)\n",
      "Using cached transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.46.0\n",
      "    Uninstalling transformers-4.46.0:\n",
      "      Successfully uninstalled transformers-4.46.0\n",
      "Successfully installed transformers-4.45.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.45.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "529bbebfb8b84e799c412f055b68dac1",
      "ed194155af9441378d6a5b07b9ed8866",
      "ab893884646c4dca9374932b6a318f2d",
      "493370fa54da4a5daae5de48e7e0d716",
      "db4e5c91141a40209fc814e29432fcca",
      "46a11e8615c94331aa76c82752da6451",
      "23954459f42b49e0bc6469f5f98ef452",
      "2e292bbcb5df405b8483d6e7fb66df9e",
      "40596f9a20e7462b8dcb6384b1778a25",
      "069c68c472424e88b5c05ec13045c0ad",
      "2ba953554175441a897015b9f3b20a50"
     ]
    },
    "id": "3AoSX0VtJ1aw",
    "outputId": "ff891889-b345-4dce-c7b9-7d956a83f234"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DAO.EZSPACE\\anaconda3\\envs\\mva2\\Lib\\site-packages\\trl\\trainer\\dpo_trainer.py:660: UserWarning: `max_length` is not set in the DPOConfig's init it will default to `512` by default, but you should do it yourself in the future.\n",
      "  warnings.warn(\n",
      "C:\\Users\\DAO.EZSPACE\\anaconda3\\envs\\mva2\\Lib\\site-packages\\trl\\trainer\\dpo_trainer.py:673: UserWarning: `max_prompt_length` is not set in the DPOConfig's init it will default to `128` by default, but you should do it yourself in the future.\n",
      "  warnings.warn(\n",
      "C:\\Users\\DAO.EZSPACE\\anaconda3\\envs\\mva2\\Lib\\site-packages\\trl\\trainer\\dpo_trainer.py:708: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17056de7893f4b598838a163a42463e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/2179 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 35:10, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.075200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.728000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.118200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.867600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.111300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.056200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.091000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.902800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.947200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.722500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.648300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.896700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.426500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.442400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.549200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.403400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.382500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.412900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.389300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.352500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.403100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.155200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.431700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.436100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.188800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.343600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.140900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.476700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.184700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.069600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.184200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.260500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.381200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.157900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.203400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.336500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.223300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.218200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.063000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.221400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.173500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.074300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.185100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.199900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.097600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.219700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.010300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.054600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.029000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.087000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.040600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.035600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.055400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.275400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.348000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.138400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.740300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.052800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.052900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.006900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.007800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.112500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.229000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.323900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.006100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.129500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.408200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.014500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.068700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.006800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.371400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.077600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.048800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.013700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.085800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.065400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.483900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.041900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.059500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.008300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.222100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.163100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.069500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.201100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.026900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.071700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.217200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.095600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.131500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.045700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.108400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.030800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.236600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.045200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.122100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.023100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.034800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.071500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.106900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.103300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.141900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.903400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.026100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.018900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.129100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.023100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.052800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.006500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.061500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.003600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0.016700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.136000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0.123000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.092900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.002900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.027800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>0.150900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>0.039800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.036200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>0.090400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>0.225200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.034000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.147600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>0.021900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.155600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>0.006800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>0.113500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>0.056000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>0.107500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.014800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>0.117300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>0.156100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>0.024400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.175300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>0.012900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>0.002700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>0.035000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>0.121800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>0.130500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.022100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>0.166100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.004800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>0.005100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>0.030500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>0.028300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.173300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>0.163800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>0.086500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>0.101400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>0.151800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>0.086200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>0.362900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>0.092500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>0.048100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>0.016900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>0.034600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.028400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>0.138300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>0.520400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>0.081700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>0.059000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>0.297200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>0.010500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>0.223000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>0.025900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.031900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>0.006000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>0.036900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.002100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>0.005800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>0.004900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>0.006400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>0.192600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.295100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=0.17563682752021123, metrics={'train_runtime': 2120.2619, 'train_samples_per_second': 0.377, 'train_steps_per_second': 0.094, 'total_flos': 0.0, 'train_loss': 0.17563682752021123, 'epoch': 0.36714089031665903})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_DIR = \"experiments_dpo\"\n",
    "\n",
    "training_args = DPOConfig(\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    save_total_limit=3,\n",
    "    logging_steps=1,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    max_steps=200,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.05,\n",
    "    report_to=\"tensorboard\",\n",
    "    beta=0.1\n",
    ")\n",
    "\n",
    "dpo_args = {\n",
    "    \"beta\": 0.1,\n",
    "}\n",
    "\n",
    "trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    train_dataset=data_dpo,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    beta=dpo_args[\"beta\"],\n",
    ") # fill the gap\n",
    "\n",
    "model.config.use_cache = False\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MswGlbg38NXx"
   },
   "source": [
    "## Test the model after DPO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "NiEYtq-yJ1aw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DAO.EZSPACE\\anaconda3\\envs\\mva2\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\DAO.EZSPACE\\anaconda3\\envs\\mva2\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<system> You are a helpful assistant\n",
      "<human>: How a house is made ?\n",
      "<assistant>:  A house is a structure designed to provide a living, living, or working environment for human habitation. It typically consists of a foundation, walls, roof, and various components such as floors, windows, doors, and insulation. The design and construction of a house can vary depending on the intended use, age, and location, but generally, it includes a structure, load-bearing components, and a system for maintaining and providing warmth, protection, and comfort.\n",
      "CPU times: total: 7.78 s\n",
      "Wall time: 8.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "device = \"cuda:0\"\n",
    "\n",
    "encoding = tokenizer(prompt_2, return_tensors=\"pt\").to(device)\n",
    "with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        input_ids=encoding.input_ids,\n",
    "        attention_mask=encoding.attention_mask,\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "-NfI1G1bJ1aw"
   },
   "outputs": [],
   "source": [
    "def generate_response(question: str) -> str:\n",
    "    prompt = f\"<human>: {question}\\n<assistant>: \"\n",
    "    encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            input_ids=encoding.input_ids,\n",
    "            attention_mask=encoding.attention_mask,\n",
    "            generation_config=generation_config,\n",
    "        )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    assistant_start = \"<assistant>:\"\n",
    "    response_start = response.find(assistant_start)\n",
    "    return response[response_start + len(assistant_start) :].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x_z0Nl1sJ1ax",
    "outputId": "397916fc-c59b-4e99-d23c-6b501c9f9de8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Do people dream in color or black and white? \n",
      "\n",
      "Dreams can be described from various perspectives, including color, black and white, or other visual or emotional aspects. Some researchers have suggested that dreams may be associated with color perception, with some individuals reporting seeing or experiencing colors in a way that is perceived as black and white. Other researchers have suggested that dreams may be associated with black and white, with some individuals reporting seeing or experiencing colors in a way that is perceived as black and white. Additionally, some researchers have suggested that dreams may be associated with other visual or emotional aspects, such as emotional expression or emotional processing.\n",
      "\n",
      "\n",
      "\n",
      "- Explain the concept of economic policies in simple terms \n",
      "\n",
      "Economic policies are strategic decisions made by governments, businesses, or other actors to influence the allocation of resources, income, and wealth within an economy. These policies can include initiatives such as fiscal policy (e.g., taxation, spending), monetary policy (e.g., interest rates, money supply), and regulatory policy (e.g., regulation of industries, antitrust enforcement). Economic policies aim to achieve various goals, such as promoting growth, reducing inequality, fostering innovation, and ensuring sustainable development.\n",
      "\n",
      "\n",
      "\n",
      "- Explain the concept of economic policies in simple terms \n",
      "\n",
      "Globalization has had a significant impact on the environment, leading to a range of global environmental issues. Some of the key effects include:\n",
      "\n",
      "1. Increased trade and trade flows: Globalization has facilitated the movement of goods, services, and capital across borders, leading to increased trade and trade flows. This has resulted in the extraction and use of resources, including energy, water, and minerals, which can contribute to environmental degradation.\n",
      "\n",
      "2. Environmental degradation: Globalization has led to the exploitation of natural resources, such as forests, minerals, and water, leading to environmental degradation. This includes the loss of biodiversity, pollution, and climate change.\n",
      "\n",
      "3. Climate change: Globalization has contributed to climate change through the emission of greenhouse gases, such as carbon dioxide and methane, which contribute to global warming. This has led to rising temperatures, sea level rise, and extreme weather events, resulting in a range of environmental impacts.\n",
      "\n",
      "4. Pollution: Globalization has led to the release of pollutants into the environment\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Do people dream in color or black and white?\"\n",
    "print('-', prompt,'\\n')\n",
    "print(generate_response(prompt))\n",
    "\n",
    "prompt = \"Explain the concept of economic policies in simple terms\"\n",
    "print('\\n\\n\\n-', prompt, '\\n')\n",
    "print(generate_response(prompt))\n",
    "\n",
    "print('\\n\\n\\n-', prompt, '\\n')\n",
    "prompt = \"Explain the effects of globalization on the environment.\"\n",
    "print(generate_response(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbFILfmBTh4R"
   },
   "source": [
    "Is the response improved after DPO?\n",
    "\n",
    "**Commentaire :**\n",
    "\n",
    "Après l'exécution du test d'inférence, les réponses fournies par le modèle DPO se révèlent beaucoup plus précises. On observe une amélioration notable dans la qualité des prédictions, avec des réponses qui démontrent une compréhension contextuelle plus fine et une pertinence accrue par rapport aux questions posées.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "u3CB1PUGTgyy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-  What equipment do I need for rock climbing?  \n",
      "\n",
      "Rock climbing involves the use of specialized equipment and gear to support and guide climbers through unstable rock surfaces. Some common equipment needed for rock climbing includes: \n",
      "- Climbing harness or harness system \n",
      "- Rock climbing harness \n",
      "- Head protection gear (e.g., helmet, chin strap) \n",
      "- Body protection gear (e.g., helmet, wrist guards) \n",
      "- Rock climbing shoes or climbing boots \n",
      "- Rock climbing poles or climbing boards \n",
      "- Rock climbing gear (e.g., crampons, belay devices) \n",
      "- Rock climbing gear for hands and feet (e.g., gloves, mitts) \n",
      "- Safety gear (e.g., helmet, wrist guards) \n",
      "- Safety harness or harness system \n",
      "- Safety gear (e.g., helmet, wrist guards) \n",
      "- Safety gear (e.g., helmet, wrist guards) \n",
      "- Safety gear (e.g., helmet, wrist guards) \n",
      "- Safety gear (e.g., helmet, wrist guards) \n",
      "- Safety gear (e.g.,\n"
     ]
    }
   ],
   "source": [
    "prompt = \" What equipment do I need for rock climbing? \"\n",
    "print('-', prompt,'\\n')\n",
    "print(generate_response(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- --------------\n",
      "absl-py                   2.1.0\n",
      "accelerate                1.0.1\n",
      "aiohappyeyeballs          2.4.3\n",
      "aiohttp                   3.10.10\n",
      "aiosignal                 1.3.1\n",
      "alphacsc                  0.4.1.dev23\n",
      "anyio                     4.6.2.post1\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "arrow                     1.3.0\n",
      "asttokens                 2.4.1\n",
      "astunparse                1.6.3\n",
      "async-lru                 2.0.4\n",
      "attrs                     24.2.0\n",
      "audioread                 3.0.1\n",
      "babel                     2.16.0\n",
      "beartype                  0.14.1\n",
      "beautifulsoup4            4.12.3\n",
      "better-abc                0.0.3\n",
      "bitsandbytes              0.44.1\n",
      "bleach                    6.1.0\n",
      "certifi                   2024.8.30\n",
      "cffi                      1.17.1\n",
      "chardet                   3.0.4\n",
      "charset-normalizer        3.4.0\n",
      "circuitsvis               1.43.2\n",
      "click                     8.1.7\n",
      "colorama                  0.4.6\n",
      "comm                      0.2.2\n",
      "contourpy                 1.3.0\n",
      "cycler                    0.12.1\n",
      "datasets                  3.0.1\n",
      "debugpy                   1.8.7\n",
      "decorator                 5.1.1\n",
      "deep-translator           1.11.4\n",
      "defusedxml                0.7.1\n",
      "dill                      0.3.8\n",
      "docker-pycreds            0.4.0\n",
      "docstring_parser          0.16\n",
      "dtw-python                1.5.3\n",
      "einops                    0.8.0\n",
      "executing                 2.1.0\n",
      "fancy-einsum              0.0.3\n",
      "fastjsonschema            2.20.0\n",
      "filelock                  3.13.1\n",
      "fire                      0.7.0\n",
      "flatbuffers               24.3.25\n",
      "fonttools                 4.54.1\n",
      "fqdn                      1.5.1\n",
      "frozenlist                1.4.1\n",
      "fsspec                    2024.2.0\n",
      "gast                      0.6.0\n",
      "gitdb                     4.0.11\n",
      "GitPython                 3.1.43\n",
      "google-pasta              0.2.0\n",
      "googletrans               3.1.0a0\n",
      "grpcio                    1.67.1\n",
      "h11                       0.9.0\n",
      "h2                        3.2.0\n",
      "h5py                      3.12.1\n",
      "hpack                     3.0.0\n",
      "hstspreload               2024.10.1\n",
      "httpcore                  0.9.1\n",
      "httpx                     0.13.3\n",
      "huggingface-hub           0.26.0\n",
      "hyperframe                5.2.0\n",
      "idna                      2.10\n",
      "importlib_metadata        8.5.0\n",
      "ipykernel                 6.29.5\n",
      "ipympl                    0.9.4\n",
      "ipython                   8.28.0\n",
      "ipython-genutils          0.2.0\n",
      "ipywidgets                8.1.5\n",
      "isoduration               20.11.0\n",
      "jaxtyping                 0.2.34\n",
      "jedi                      0.19.1\n",
      "Jinja2                    3.1.3\n",
      "joblib                    1.4.2\n",
      "json5                     0.9.25\n",
      "jsonpointer               3.0.0\n",
      "jsonschema                4.23.0\n",
      "jsonschema-specifications 2024.10.1\n",
      "jupyter                   1.1.1\n",
      "jupyter_client            8.6.3\n",
      "jupyter-console           6.6.3\n",
      "jupyter_core              5.7.2\n",
      "jupyter-events            0.10.0\n",
      "jupyter-lsp               2.2.5\n",
      "jupyter_server            2.14.2\n",
      "jupyter_server_terminals  0.5.3\n",
      "jupyter-translate         2024.0.1\n",
      "jupyterlab                4.2.5\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.27.3\n",
      "jupyterlab_widgets        3.0.13\n",
      "keras                     3.6.0\n",
      "kiwisolver                1.4.7\n",
      "lab                       8.2\n",
      "lazy_loader               0.4\n",
      "libclang                  18.1.1\n",
      "librosa                   0.10.2.post1\n",
      "llvmlite                  0.43.0\n",
      "loadmydata                0.0.11\n",
      "loralib                   0.1.2\n",
      "Markdown                  3.7\n",
      "markdown-it-py            3.0.0\n",
      "MarkupSafe                2.1.5\n",
      "matplotlib                3.9.2\n",
      "matplotlib-inline         0.1.7\n",
      "mdurl                     0.1.2\n",
      "mistune                   3.0.2\n",
      "ml-dtypes                 0.4.1\n",
      "mne                       1.8.0\n",
      "mpmath                    1.3.0\n",
      "msgpack                   1.1.0\n",
      "multidict                 6.1.0\n",
      "multiprocess              0.70.16\n",
      "namex                     0.0.8\n",
      "nbclient                  0.10.0\n",
      "nbconvert                 7.16.4\n",
      "nbformat                  5.10.4\n",
      "nest-asyncio              1.6.0\n",
      "networkx                  3.2.1\n",
      "nodejs-bin                18.4.0a4\n",
      "notebook                  7.2.2\n",
      "notebook_shim             0.2.4\n",
      "numba                     0.60.0\n",
      "numpy                     1.26.3\n",
      "opt_einsum                3.4.0\n",
      "optree                    0.13.0\n",
      "overrides                 7.7.0\n",
      "packaging                 24.1\n",
      "pandas                    2.2.3\n",
      "pandocfilters             1.5.1\n",
      "parso                     0.8.4\n",
      "patsy                     0.5.6\n",
      "peft                      0.13.2\n",
      "pillow                    10.2.0\n",
      "pip                       24.2\n",
      "platformdirs              4.3.6\n",
      "pooch                     1.8.2\n",
      "prometheus_client         0.21.0\n",
      "prompt_toolkit            3.0.48\n",
      "propcache                 0.2.0\n",
      "protobuf                  5.28.2\n",
      "psutil                    6.0.0\n",
      "pure_eval                 0.2.3\n",
      "pyarrow                   17.0.0\n",
      "pycparser                 2.22\n",
      "Pygments                  2.18.0\n",
      "pyparsing                 3.2.0\n",
      "python-dateutil           2.9.0.post0\n",
      "python-json-logger        2.0.7\n",
      "pytz                      2024.2\n",
      "pywin32                   308\n",
      "pywinpty                  2.0.13\n",
      "PyYAML                    6.0.2\n",
      "pyzmq                     26.2.0\n",
      "referencing               0.35.1\n",
      "regex                     2024.9.11\n",
      "requests                  2.32.3\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986                   1.5.0\n",
      "rfc3986-validator         0.1.1\n",
      "rich                      13.9.2\n",
      "rpds-py                   0.20.0\n",
      "safetensors               0.4.5\n",
      "scikit-learn              1.5.2\n",
      "scipy                     1.14.1\n",
      "seaborn                   0.13.2\n",
      "Send2Trash                1.8.3\n",
      "sentencepiece             0.2.0\n",
      "sentry-sdk                2.17.0\n",
      "setproctitle              1.3.3\n",
      "setuptools                75.1.0\n",
      "shtab                     1.7.1\n",
      "simplejson                3.19.3\n",
      "six                       1.16.0\n",
      "smmap                     5.0.1\n",
      "sniffio                   1.3.1\n",
      "soundfile                 0.12.1\n",
      "soupsieve                 2.6\n",
      "soxr                      0.5.0.post1\n",
      "stack-data                0.6.3\n",
      "statsmodels               0.14.4\n",
      "sympy                     1.12\n",
      "tensorboard               2.18.0\n",
      "tensorboard-data-server   0.7.2\n",
      "tensorflow                2.18.0\n",
      "tensorflow_intel          2.18.0\n",
      "termcolor                 2.5.0\n",
      "terminado                 0.18.1\n",
      "tf_keras                  2.18.0\n",
      "threadpoolctl             3.5.0\n",
      "tinycss2                  1.3.0\n",
      "tokenizers                0.20.1\n",
      "torch                     2.4.1+cu118\n",
      "torchaudio                2.4.1+cu118\n",
      "torchvision               0.19.1+cu118\n",
      "tornado                   6.4.1\n",
      "tqdm                      4.66.5\n",
      "traitlets                 5.14.3\n",
      "transformer-lens          2.7.0\n",
      "transformers              4.45.2\n",
      "trl                       0.11.4\n",
      "txt2tags                  3.9\n",
      "typeguard                 2.13.3\n",
      "types-python-dateutil     2.9.0.20241003\n",
      "typing_extensions         4.9.0\n",
      "tyro                      0.8.14\n",
      "tzdata                    2024.2\n",
      "uri-template              1.3.0\n",
      "urllib3                   2.2.3\n",
      "wandb                     0.18.5\n",
      "wcwidth                   0.2.13\n",
      "webcolors                 24.8.0\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.8.0\n",
      "Werkzeug                  3.0.6\n",
      "wheel                     0.44.0\n",
      "widgetsnbextension        4.0.13\n",
      "wrapt                     1.16.0\n",
      "xxhash                    3.5.0\n",
      "yarl                      1.15.4\n",
      "zipp                      3.20.2\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at C:\\Users\\DAO.EZSPACE\\anaconda3\\envs\\mva2:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "absl-py                   2.1.0                    pypi_0    pypi\n",
      "accelerate                1.0.1                    pypi_0    pypi\n",
      "aiohappyeyeballs          2.4.3                    pypi_0    pypi\n",
      "aiohttp                   3.10.10                  pypi_0    pypi\n",
      "aiosignal                 1.3.1                    pypi_0    pypi\n",
      "alphacsc                  0.4.1.dev23              pypi_0    pypi\n",
      "anaconda_prompt           1.1.0                haa95532_0  \n",
      "anyio                     4.6.2.post1              pypi_0    pypi\n",
      "argon2-cffi               23.1.0                   pypi_0    pypi\n",
      "argon2-cffi-bindings      21.2.0                   pypi_0    pypi\n",
      "arrow                     1.3.0                    pypi_0    pypi\n",
      "asttokens                 2.4.1                    pypi_0    pypi\n",
      "astunparse                1.6.3                    pypi_0    pypi\n",
      "async-lru                 2.0.4                    pypi_0    pypi\n",
      "attrs                     24.2.0                   pypi_0    pypi\n",
      "audioread                 3.0.1                    pypi_0    pypi\n",
      "babel                     2.16.0                   pypi_0    pypi\n",
      "beartype                  0.14.1                   pypi_0    pypi\n",
      "beautifulsoup4            4.12.3                   pypi_0    pypi\n",
      "better-abc                0.0.3                    pypi_0    pypi\n",
      "bitsandbytes              0.44.1                   pypi_0    pypi\n",
      "bleach                    6.1.0                    pypi_0    pypi\n",
      "bzip2                     1.0.8                h2bbff1b_6  \n",
      "ca-certificates           2024.9.24            haa95532_0  \n",
      "certifi                   2024.8.30                pypi_0    pypi\n",
      "cffi                      1.17.1                   pypi_0    pypi\n",
      "chardet                   3.0.4                    pypi_0    pypi\n",
      "charset-normalizer        3.4.0                    pypi_0    pypi\n",
      "circuitsvis               1.43.2                   pypi_0    pypi\n",
      "click                     8.1.7                    pypi_0    pypi\n",
      "colorama                  0.4.6                    pypi_0    pypi\n",
      "comm                      0.2.2                    pypi_0    pypi\n",
      "contourpy                 1.3.0                    pypi_0    pypi\n",
      "cycler                    0.12.1                   pypi_0    pypi\n",
      "datasets                  3.0.1                    pypi_0    pypi\n",
      "debugpy                   1.8.7                    pypi_0    pypi\n",
      "decorator                 5.1.1                    pypi_0    pypi\n",
      "deep-translator           1.11.4                   pypi_0    pypi\n",
      "defusedxml                0.7.1                    pypi_0    pypi\n",
      "dill                      0.3.8                    pypi_0    pypi\n",
      "docker-pycreds            0.4.0                    pypi_0    pypi\n",
      "docstring-parser          0.16                     pypi_0    pypi\n",
      "dtw-python                1.5.3                    pypi_0    pypi\n",
      "einops                    0.8.0                    pypi_0    pypi\n",
      "executing                 2.1.0                    pypi_0    pypi\n",
      "expat                     2.6.3                h5da7b33_0  \n",
      "fancy-einsum              0.0.3                    pypi_0    pypi\n",
      "fastjsonschema            2.20.0                   pypi_0    pypi\n",
      "filelock                  3.13.1                   pypi_0    pypi\n",
      "fire                      0.7.0                    pypi_0    pypi\n",
      "flatbuffers               24.3.25                  pypi_0    pypi\n",
      "fonttools                 4.54.1                   pypi_0    pypi\n",
      "fqdn                      1.5.1                    pypi_0    pypi\n",
      "frozenlist                1.4.1                    pypi_0    pypi\n",
      "fsspec                    2024.2.0                 pypi_0    pypi\n",
      "gast                      0.6.0                    pypi_0    pypi\n",
      "git                       2.45.2               haa95532_1  \n",
      "gitdb                     4.0.11                   pypi_0    pypi\n",
      "gitpython                 3.1.43                   pypi_0    pypi\n",
      "google-pasta              0.2.0                    pypi_0    pypi\n",
      "googletrans               3.1.0a0                  pypi_0    pypi\n",
      "grpcio                    1.67.1                   pypi_0    pypi\n",
      "h11                       0.9.0                    pypi_0    pypi\n",
      "h2                        3.2.0                    pypi_0    pypi\n",
      "h5py                      3.12.1                   pypi_0    pypi\n",
      "hpack                     3.0.0                    pypi_0    pypi\n",
      "hstspreload               2024.10.1                pypi_0    pypi\n",
      "httpcore                  0.9.1                    pypi_0    pypi\n",
      "httpx                     0.13.3                   pypi_0    pypi\n",
      "huggingface-hub           0.26.0                   pypi_0    pypi\n",
      "hyperframe                5.2.0                    pypi_0    pypi\n",
      "idna                      2.10                     pypi_0    pypi\n",
      "importlib-metadata        8.5.0                    pypi_0    pypi\n",
      "ipykernel                 6.29.5                   pypi_0    pypi\n",
      "ipympl                    0.9.4                    pypi_0    pypi\n",
      "ipython                   8.28.0                   pypi_0    pypi\n",
      "ipython-genutils          0.2.0                    pypi_0    pypi\n",
      "ipywidgets                8.1.5                    pypi_0    pypi\n",
      "isoduration               20.11.0                  pypi_0    pypi\n",
      "jaxtyping                 0.2.34                   pypi_0    pypi\n",
      "jedi                      0.19.1                   pypi_0    pypi\n",
      "jinja2                    3.1.3                    pypi_0    pypi\n",
      "joblib                    1.4.2                    pypi_0    pypi\n",
      "json5                     0.9.25                   pypi_0    pypi\n",
      "jsonpointer               3.0.0                    pypi_0    pypi\n",
      "jsonschema                4.23.0                   pypi_0    pypi\n",
      "jsonschema-specifications 2024.10.1                pypi_0    pypi\n",
      "jupyter                   1.1.1                    pypi_0    pypi\n",
      "jupyter-client            8.6.3                    pypi_0    pypi\n",
      "jupyter-console           6.6.3                    pypi_0    pypi\n",
      "jupyter-core              5.7.2                    pypi_0    pypi\n",
      "jupyter-events            0.10.0                   pypi_0    pypi\n",
      "jupyter-lsp               2.2.5                    pypi_0    pypi\n",
      "jupyter-server            2.14.2                   pypi_0    pypi\n",
      "jupyter-server-terminals  0.5.3                    pypi_0    pypi\n",
      "jupyter-translate         2024.0.1                 pypi_0    pypi\n",
      "jupyterlab                4.2.5                    pypi_0    pypi\n",
      "jupyterlab-pygments       0.3.0                    pypi_0    pypi\n",
      "jupyterlab-server         2.27.3                   pypi_0    pypi\n",
      "jupyterlab-widgets        3.0.13                   pypi_0    pypi\n",
      "keras                     3.6.0                    pypi_0    pypi\n",
      "kiwisolver                1.4.7                    pypi_0    pypi\n",
      "lab                       8.2                      pypi_0    pypi\n",
      "lazy-loader               0.4                      pypi_0    pypi\n",
      "libclang                  18.1.1                   pypi_0    pypi\n",
      "libffi                    3.4.4                hd77b12b_1  \n",
      "librosa                   0.10.2.post1             pypi_0    pypi\n",
      "llvmlite                  0.43.0                   pypi_0    pypi\n",
      "loadmydata                0.0.11                   pypi_0    pypi\n",
      "loralib                   0.1.2                    pypi_0    pypi\n",
      "markdown                  3.7                      pypi_0    pypi\n",
      "markdown-it-py            3.0.0                    pypi_0    pypi\n",
      "markupsafe                2.1.5                    pypi_0    pypi\n",
      "matplotlib                3.9.2                    pypi_0    pypi\n",
      "matplotlib-inline         0.1.7                    pypi_0    pypi\n",
      "mdurl                     0.1.2                    pypi_0    pypi\n",
      "mistune                   3.0.2                    pypi_0    pypi\n",
      "ml-dtypes                 0.4.1                    pypi_0    pypi\n",
      "mne                       1.8.0                    pypi_0    pypi\n",
      "mpmath                    1.3.0                    pypi_0    pypi\n",
      "msgpack                   1.1.0                    pypi_0    pypi\n",
      "multidict                 6.1.0                    pypi_0    pypi\n",
      "multiprocess              0.70.16                  pypi_0    pypi\n",
      "namex                     0.0.8                    pypi_0    pypi\n",
      "nbclient                  0.10.0                   pypi_0    pypi\n",
      "nbconvert                 7.16.4                   pypi_0    pypi\n",
      "nbformat                  5.10.4                   pypi_0    pypi\n",
      "nest-asyncio              1.6.0                    pypi_0    pypi\n",
      "networkx                  3.2.1                    pypi_0    pypi\n",
      "nodejs-bin                18.4.0a4                 pypi_0    pypi\n",
      "notebook                  7.2.2                    pypi_0    pypi\n",
      "notebook-shim             0.2.4                    pypi_0    pypi\n",
      "numba                     0.60.0                   pypi_0    pypi\n",
      "numpy                     1.26.3                   pypi_0    pypi\n",
      "openssl                   3.0.15               h827c3e9_0  \n",
      "opt-einsum                3.4.0                    pypi_0    pypi\n",
      "optree                    0.13.0                   pypi_0    pypi\n",
      "overrides                 7.7.0                    pypi_0    pypi\n",
      "packaging                 24.1                     pypi_0    pypi\n",
      "pandas                    2.2.3                    pypi_0    pypi\n",
      "pandocfilters             1.5.1                    pypi_0    pypi\n",
      "parso                     0.8.4                    pypi_0    pypi\n",
      "patsy                     0.5.6                    pypi_0    pypi\n",
      "peft                      0.13.2                   pypi_0    pypi\n",
      "pillow                    10.2.0                   pypi_0    pypi\n",
      "pip                       24.2            py312haa95532_0  \n",
      "platformdirs              4.3.6                    pypi_0    pypi\n",
      "pooch                     1.8.2                    pypi_0    pypi\n",
      "prometheus-client         0.21.0                   pypi_0    pypi\n",
      "prompt-toolkit            3.0.48                   pypi_0    pypi\n",
      "propcache                 0.2.0                    pypi_0    pypi\n",
      "protobuf                  5.28.2                   pypi_0    pypi\n",
      "psutil                    6.0.0                    pypi_0    pypi\n",
      "pure-eval                 0.2.3                    pypi_0    pypi\n",
      "pyarrow                   17.0.0                   pypi_0    pypi\n",
      "pycparser                 2.22                     pypi_0    pypi\n",
      "pygments                  2.18.0                   pypi_0    pypi\n",
      "pyparsing                 3.2.0                    pypi_0    pypi\n",
      "python                    3.12.7               h14ffc60_0  \n",
      "python-dateutil           2.9.0.post0              pypi_0    pypi\n",
      "python-json-logger        2.0.7                    pypi_0    pypi\n",
      "pytz                      2024.2                   pypi_0    pypi\n",
      "pywin32                   308                      pypi_0    pypi\n",
      "pywinpty                  2.0.13                   pypi_0    pypi\n",
      "pyyaml                    6.0.2                    pypi_0    pypi\n",
      "pyzmq                     26.2.0                   pypi_0    pypi\n",
      "referencing               0.35.1                   pypi_0    pypi\n",
      "regex                     2024.9.11                pypi_0    pypi\n",
      "requests                  2.32.3                   pypi_0    pypi\n",
      "rfc3339-validator         0.1.4                    pypi_0    pypi\n",
      "rfc3986                   1.5.0                    pypi_0    pypi\n",
      "rfc3986-validator         0.1.1                    pypi_0    pypi\n",
      "rich                      13.9.2                   pypi_0    pypi\n",
      "rpds-py                   0.20.0                   pypi_0    pypi\n",
      "safetensors               0.4.5                    pypi_0    pypi\n",
      "scikit-learn              1.5.2                    pypi_0    pypi\n",
      "scipy                     1.14.1                   pypi_0    pypi\n",
      "seaborn                   0.13.2                   pypi_0    pypi\n",
      "send2trash                1.8.3                    pypi_0    pypi\n",
      "sentencepiece             0.2.0                    pypi_0    pypi\n",
      "sentry-sdk                2.17.0                   pypi_0    pypi\n",
      "setproctitle              1.3.3                    pypi_0    pypi\n",
      "setuptools                75.1.0          py312haa95532_0  \n",
      "shtab                     1.7.1                    pypi_0    pypi\n",
      "simplejson                3.19.3                   pypi_0    pypi\n",
      "six                       1.16.0                   pypi_0    pypi\n",
      "smmap                     5.0.1                    pypi_0    pypi\n",
      "sniffio                   1.3.1                    pypi_0    pypi\n",
      "soundfile                 0.12.1                   pypi_0    pypi\n",
      "soupsieve                 2.6                      pypi_0    pypi\n",
      "soxr                      0.5.0.post1              pypi_0    pypi\n",
      "sqlite                    3.45.3               h2bbff1b_0  \n",
      "stack-data                0.6.3                    pypi_0    pypi\n",
      "statsmodels               0.14.4                   pypi_0    pypi\n",
      "sympy                     1.12                     pypi_0    pypi\n",
      "tensorboard               2.18.0                   pypi_0    pypi\n",
      "tensorboard-data-server   0.7.2                    pypi_0    pypi\n",
      "tensorflow                2.18.0                   pypi_0    pypi\n",
      "tensorflow-intel          2.18.0                   pypi_0    pypi\n",
      "termcolor                 2.5.0                    pypi_0    pypi\n",
      "terminado                 0.18.1                   pypi_0    pypi\n",
      "tf-keras                  2.18.0                   pypi_0    pypi\n",
      "threadpoolctl             3.5.0                    pypi_0    pypi\n",
      "tinycss2                  1.3.0                    pypi_0    pypi\n",
      "tk                        8.6.14               h0416ee5_0  \n",
      "tokenizers                0.20.1                   pypi_0    pypi\n",
      "torch                     2.4.1+cu118              pypi_0    pypi\n",
      "torchaudio                2.4.1+cu118              pypi_0    pypi\n",
      "torchvision               0.19.1+cu118             pypi_0    pypi\n",
      "tornado                   6.4.1                    pypi_0    pypi\n",
      "tqdm                      4.66.5                   pypi_0    pypi\n",
      "traitlets                 5.14.3                   pypi_0    pypi\n",
      "transformer-lens          2.7.0                    pypi_0    pypi\n",
      "transformers              4.45.2                   pypi_0    pypi\n",
      "trl                       0.11.4                   pypi_0    pypi\n",
      "txt2tags                  3.9                      pypi_0    pypi\n",
      "typeguard                 2.13.3                   pypi_0    pypi\n",
      "types-python-dateutil     2.9.0.20241003           pypi_0    pypi\n",
      "typing-extensions         4.9.0                    pypi_0    pypi\n",
      "tyro                      0.8.14                   pypi_0    pypi\n",
      "tzdata                    2024.2                   pypi_0    pypi\n",
      "uri-template              1.3.0                    pypi_0    pypi\n",
      "urllib3                   2.2.3                    pypi_0    pypi\n",
      "vc                        14.40                h2eaa2aa_1  \n",
      "vs2015_runtime            14.40.33807          h98bb1dd_1  \n",
      "wandb                     0.18.5                   pypi_0    pypi\n",
      "wcwidth                   0.2.13                   pypi_0    pypi\n",
      "webcolors                 24.8.0                   pypi_0    pypi\n",
      "webencodings              0.5.1                    pypi_0    pypi\n",
      "websocket-client          1.8.0                    pypi_0    pypi\n",
      "werkzeug                  3.0.6                    pypi_0    pypi\n",
      "wheel                     0.44.0          py312haa95532_0  \n",
      "widgetsnbextension        4.0.13                   pypi_0    pypi\n",
      "wrapt                     1.16.0                   pypi_0    pypi\n",
      "xxhash                    3.5.0                    pypi_0    pypi\n",
      "xz                        5.4.6                h8cc25b3_1  \n",
      "yarl                      1.15.4                   pypi_0    pypi\n",
      "zipp                      3.20.2                   pypi_0    pypi\n",
      "zlib                      1.2.13               h8cc25b3_1  \n"
     ]
    }
   ],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "069c68c472424e88b5c05ec13045c0ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23954459f42b49e0bc6469f5f98ef452": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2ba953554175441a897015b9f3b20a50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2e292bbcb5df405b8483d6e7fb66df9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40596f9a20e7462b8dcb6384b1778a25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "46a11e8615c94331aa76c82752da6451": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "493370fa54da4a5daae5de48e7e0d716": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_069c68c472424e88b5c05ec13045c0ad",
      "placeholder": "​",
      "style": "IPY_MODEL_2ba953554175441a897015b9f3b20a50",
      "value": " 2179/2179 [00:02&lt;00:00, 926.74 examples/s]"
     }
    },
    "529bbebfb8b84e799c412f055b68dac1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ed194155af9441378d6a5b07b9ed8866",
       "IPY_MODEL_ab893884646c4dca9374932b6a318f2d",
       "IPY_MODEL_493370fa54da4a5daae5de48e7e0d716"
      ],
      "layout": "IPY_MODEL_db4e5c91141a40209fc814e29432fcca"
     }
    },
    "ab893884646c4dca9374932b6a318f2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e292bbcb5df405b8483d6e7fb66df9e",
      "max": 2179,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_40596f9a20e7462b8dcb6384b1778a25",
      "value": 2179
     }
    },
    "db4e5c91141a40209fc814e29432fcca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed194155af9441378d6a5b07b9ed8866": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46a11e8615c94331aa76c82752da6451",
      "placeholder": "​",
      "style": "IPY_MODEL_23954459f42b49e0bc6469f5f98ef452",
      "value": "Tokenizing train dataset: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
