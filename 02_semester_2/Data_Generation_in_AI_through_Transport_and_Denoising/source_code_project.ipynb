{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report for DataChallenge SLB EchoCEM\n",
    "\n",
    "**Student :** CHOQUET Laura and GRAVIER Thomas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import segmentation_models_pytorch as smp\n",
    "from tqdm import tqdm\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I - Load Data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(\"y_train.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_DIR = os.getcwd()\n",
    "DIR_train = \"/datasets/train\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, y_train, train=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): Dossier contenant les fichiers .npy.\n",
    "            y_train (pd.DataFrame): DataFrame contenant les masques sous forme de lignes flatten.\n",
    "            train (bool): Si True, charge l'ensemble d'entraînement, sinon charge la validation.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.y_train = y_train  \n",
    "        self.train = train  \n",
    "\n",
    "        self.train_files = [f for f in os.listdir(root_dir) if f.endswith(\".npy\")]\n",
    "        self.train_files = [f for f in os.listdir(root_dir) if f.startswith((\"well_1\", \"well_4\",\"well_6\",\"well_2\")) and f.endswith(\".npy\")]\n",
    "        self.val_files = [f for f in os.listdir(root_dir) if f.startswith((\"well_5\")) and f.endswith(\".npy\")]\n",
    "        self.files = self.train_files if train else self.val_files\n",
    "\n",
    "        self.resize_transform = transforms.Resize((160, 160), interpolation=transforms.InterpolationMode.BILINEAR)\n",
    "        self.resize_label_transform = transforms.Resize((160, 160), interpolation=transforms.InterpolationMode.NEAREST)\n",
    "\n",
    "        self.augmentations = A.Compose([\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.4),\n",
    "\n",
    "            A.GridDistortion(p=0.3),\n",
    "\n",
    "            A.GaussianBlur(blur_limit=(3, 5), p=0.2),\n",
    "            A.GaussNoise(var_limit=(5.0, 30.0), p=0.2),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.3),\n",
    "            A.CLAHE(clip_limit=2.0, tile_grid_size=(8,8), p=0.2),\n",
    "            \n",
    "            A.RandomShadow(p=0.1),  # Ajout d'ombres aléatoires\n",
    "            A.Sharpen(alpha=(0.2, 0.5), p=0.2),  # Rehausse les détails\n",
    "            A.RandomGamma(gamma_limit=(80, 120), p=0.2),  # Ajustement gamma\n",
    "        ])\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.files[idx]\n",
    "        file_path = os.path.join(self.root_dir, file_name)\n",
    "\n",
    "        image = np.load(file_path).astype(np.float32)\n",
    "        original_size = image.shape\n",
    "        resized = False  \n",
    "\n",
    "        image_min, image_max = image.min(), image.max()\n",
    "        if image_max > image_min:  \n",
    "            image = (image - image_min) / (image_max - image_min)\n",
    "        else:\n",
    "            image = np.zeros_like(image) \n",
    "\n",
    "        image = torch.tensor(image, dtype=torch.float32).unsqueeze(0)  \n",
    "\n",
    "        if original_size != (160, 160):\n",
    "            image = self.resize_transform(image)\n",
    "            resized = True  \n",
    "\n",
    "        file_id = os.path.splitext(file_name)[0]\n",
    "        label_flatten = self.y_train.loc[file_id].values.astype(np.int64)\n",
    "\n",
    "        if np.any(label_flatten == -1):\n",
    "            label_flatten = label_flatten[:np.argmax(label_flatten == -1)]\n",
    "\n",
    "        if label_flatten.size == 160 * 272:\n",
    "            label_shape = (160, 272)\n",
    "        else:\n",
    "            label_shape = (160, 160)\n",
    "\n",
    "        label = label_flatten.reshape(label_shape)\n",
    "        label = torch.tensor(label, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        if label_shape != (160, 160):\n",
    "            label = self.resize_label_transform(label)\n",
    "\n",
    "        if self.train:\n",
    "            augmented = self.augmentations(image=image.numpy().transpose(1, 2, 0), mask=label.numpy().transpose(1, 2, 0))\n",
    "            image = torch.tensor(augmented[\"image\"]).permute(2, 0, 1)  \n",
    "            label = torch.tensor(augmented[\"mask\"]).permute(2, 0, 1)  \n",
    "\n",
    "        return {\n",
    "            \"image\": image,\n",
    "            \"resized\": resized,\n",
    "            \"label\": label\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = CustomImageDataset(\"images train\", y_train, train=True)  \n",
    "val_dataset = CustomImageDataset(\"images train\", y_train, train=False)  \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "\n",
    "print(f\"Taille du dataset d'entraînement : {len(train_dataset)}\")\n",
    "print(f\"Taille du dataset de validation : {len(val_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II - Processing with UNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model choisie : RESNET + pretraine image net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Utilisation de : {device}\")\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\"\"\" model = smp.UnetPlusPlus(\n",
    "    encoder_name=\"efficientnet-b4\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=1,\n",
    "    classes=3\n",
    ").to(device)\n",
    "model = smp.DeepLabV3Plus(\n",
    "    encoder_name=\"resnet101\",  # ResNet50 si vous voulez un modèle plus rapide\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=1,\n",
    "    classes=3  # Nombre de classes de segmentation\n",
    ").to(device)\n",
    " \"\"\"\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",       \n",
    "    encoder_weights=\"imagenet\",    \n",
    "    in_channels=1,                 \n",
    "    classes=3                      \n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def focal_dice_loss(preds, targets, alpha=0.5, gamma=2.0):\n",
    "    targets_cls = targets.squeeze(1).long()\n",
    "    ce_loss = F.cross_entropy(preds, targets_cls, reduction='none')\n",
    "    pt = torch.exp(-ce_loss)\n",
    "    focal_loss = ((1 - pt) ** gamma) * ce_loss\n",
    "    focal_component = focal_loss.mean()\n",
    "    \n",
    "    preds_soft = F.softmax(preds, dim=1)\n",
    "    targets_one_hot = F.one_hot(targets_cls, num_classes=3).permute(0, 3, 1, 2).float()\n",
    "    \n",
    "    intersection = (preds_soft * targets_one_hot).sum(dim=(2, 3))\n",
    "    cardinality = preds_soft.sum(dim=(2, 3)) + targets_one_hot.sum(dim=(2, 3))\n",
    "    \n",
    "    dice = 2 * intersection / (cardinality + 1e-6)\n",
    "    dice_component = (1 - dice.mean())\n",
    "    \n",
    "    return alpha * focal_component + (1 - alpha) * dice_component\n",
    "\n",
    "def compute_multiclass_iou(preds, targets, num_classes=3, ignore_bg=True):\n",
    "    preds = torch.argmax(preds, dim=1)  \n",
    "    targets = targets.squeeze(1).long()  \n",
    "    \n",
    "    class_ious = []\n",
    "    \n",
    "    for cls in range(num_classes):\n",
    "        pred_mask = (preds == cls).float()\n",
    "        target_mask = (targets == cls).float()\n",
    "        \n",
    "        intersection = (pred_mask * target_mask).sum((1, 2))\n",
    "        union = ((pred_mask + target_mask) > 0).float().sum((1, 2))\n",
    "        \n",
    "        iou = (intersection + 1e-6) / (union + 1e-6)\n",
    "        \n",
    "        class_ious.append(iou.mean().item())\n",
    "    \n",
    "    if ignore_bg:\n",
    "        mean_iou = sum(class_ious[1:]) / (num_classes - 1) \n",
    "    else:\n",
    "        mean_iou = sum(class_ious) / num_classes  \n",
    "    \n",
    "    return mean_iou, class_ious\n",
    "\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, scheduler, num_epochs=20, checkpoint_path=\"best_model.pth\"):\n",
    "    best_iou = 0.0  \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        loop = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\", leave=False)\n",
    "\n",
    "        for batch in loop:\n",
    "            images, masks, resized = batch[\"image\"], batch[\"label\"], batch[\"resized\"]\n",
    "\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = focal_dice_loss(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            loop.set_postfix(loss=loss.item(), resized=resized.sum().item())\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}: Training Loss = {avg_loss:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        iou_score = 0.0\n",
    "        iou_1, iou_2, iou_3 = 0.0, 0.0, 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                images, masks, resized = batch[\"image\"], batch[\"label\"], batch[\"resized\"]\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                outputs = model(images)\n",
    "                iou_mean,iou_class= compute_multiclass_iou(outputs, masks)\n",
    "                iou_score+=iou_mean\n",
    "                iou_1 += iou_class[0]\n",
    "                iou_2 += iou_class[1]\n",
    "                iou_3 += iou_class[2]\n",
    "        avg_iou = iou_score / len(val_loader)\n",
    "        avg_iou_1 = iou_1 / len(val_loader)\n",
    "        avg_iou_2 = iou_2 / len(val_loader)\n",
    "        avg_iou_3 = iou_3 / len(val_loader)\n",
    "        print(f\"Validation Mean IoU = {avg_iou:.4f}, Mean IoU 1 = {avg_iou_1:.4f}, Mean IoU 2 = {avg_iou_2:.4f} Mean IoU 3 = {avg_iou_3:.4f}\")\n",
    "\n",
    "        scheduler.step(avg_iou)\n",
    "\n",
    "        if avg_iou_1 > best_iou:\n",
    "            best_iou = avg_iou_1\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f\" Meilleur modèle sauvegardé à epoch {epoch+1} avec IoU 2 {best_iou:.4f}\")\n",
    "\n",
    "        if epoch == 5:\n",
    "            print(\" Déblocage partiel du backbone pour fine-tuning progressif.\")\n",
    "            for param in list(model.encoder.parameters())[-10:]:  # Dernières couches seulement\n",
    "                param.requires_grad = True\n",
    "\n",
    "        if epoch == 10:\n",
    "            print(\" Déblocage total du backbone.\")\n",
    "            for param in model.encoder.parameters():\n",
    "                param.requires_grad = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Utilisation de : {device}\")\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",       \n",
    "    encoder_weights=None,          \n",
    "    in_channels=1,                 \n",
    "    classes=3                      \n",
    ").to(device)\n",
    "\n",
    "checkpoint_path = \"best_model_0_682/best_model.pth\"\n",
    "if os.path.isfile(checkpoint_path):\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    print(f\" Poids pré-entraînés chargés depuis {checkpoint_path}.\")\n",
    "else:\n",
    "    print(f\" Aucun fichier de poids pré-entraînés trouvé à l'emplacement : {checkpoint_path}. Veuillez vérifier le chemin.\")\n",
    "\n",
    "def compute_multiclass_iou(preds, targets, num_classes=3, ignore_bg=True):\n",
    "    preds = torch.argmax(preds, dim=1)  \n",
    "    targets = targets.squeeze(1).long()  \n",
    "    \n",
    "    class_ious = []\n",
    "    \n",
    "    for cls in range(num_classes):\n",
    "        pred_mask = (preds == cls).float()\n",
    "        target_mask = (targets == cls).float()\n",
    "        \n",
    "        intersection = (pred_mask * target_mask).sum((1, 2))\n",
    "        union = ((pred_mask + target_mask) > 0).float().sum((1, 2))\n",
    "        \n",
    "        iou = (intersection + 1e-6) / (union + 1e-6)\n",
    "        \n",
    "        class_ious.append(iou.mean().item())\n",
    "    \n",
    "    if ignore_bg:\n",
    "        mean_iou = sum(class_ious[1:]) / (num_classes - 1)\n",
    "    else:\n",
    "        mean_iou = sum(class_ious) / num_classes  \n",
    "    \n",
    "    return mean_iou, class_ious\n",
    "\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    iou_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images, masks, _ = batch[\"image\"], batch[\"label\"], batch[\"resized\"]\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            iou,_ = compute_multiclass_iou(outputs, masks)\n",
    "            iou_list.append(iou)\n",
    "    \n",
    "    # Calcul de l'IoU moyen\n",
    "    mean_iou = sum(iou_list) / len(iou_list)\n",
    "    print(f\" Moyenne de l'IoU sur l'ensemble du val_loader : {mean_iou:.4f}\")\n",
    "\n",
    "# Exécution de l'évaluation\n",
    "evaluate(model, val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III -  Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_edges(x):\n",
    "    \"\"\"\n",
    "    Applique un filtre Sobel sur chaque canal indépendamment.\n",
    "    \"\"\"\n",
    "    sobel_x = torch.tensor([[1, 0, -1], [2, 0, -2], [1, 0, -1]], dtype=torch.float32).repeat(x.shape[1], 1, 1, 1).to(x.device)\n",
    "    sobel_y = torch.tensor([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], dtype=torch.float32).repeat(x.shape[1], 1, 1, 1).to(x.device)\n",
    "\n",
    "    edge_x = F.conv2d(x, sobel_x, padding=1, groups=x.shape[1])  # Appliquer indépendamment sur chaque canal\n",
    "    edge_y = F.conv2d(x, sobel_y, padding=1, groups=x.shape[1])\n",
    "    \n",
    "    return torch.sqrt(edge_x**2 + edge_y**2 + 1e-6)  # Norme L2 pour éviter torch.abs\n",
    "\n",
    "def boundary_loss(preds, targets):\n",
    "    \"\"\"\n",
    "    Perte qui compare les bords des prédictions et des cibles.\n",
    "    \"\"\"\n",
    "    preds_soft = torch.softmax(preds, dim=1)  # Probabilités par classe\n",
    "    \n",
    "    targets_cls = targets.squeeze(1).long()\n",
    "    targets_one_hot = F.one_hot(targets_cls, num_classes=preds.shape[1]).permute(0, 3, 1, 2).float()\n",
    "\n",
    "    # On utilise seulement la classe la plus probable pour éviter d’inclure trop de bruit\n",
    "    preds_max = preds_soft.argmax(dim=1, keepdim=True)\n",
    "    preds_one_hot = F.one_hot(preds_max.squeeze(1), num_classes=preds.shape[1]).permute(0, 3, 1, 2).float()\n",
    "\n",
    "    # Contours\n",
    "    edge_preds = compute_edges(preds_one_hot)\n",
    "    edge_targets = compute_edges(targets_one_hot)\n",
    "\n",
    "    # Différence entre contours en norme L2\n",
    "    edge_diff = (edge_preds - edge_targets) ** 2  \n",
    "\n",
    "    return edge_diff.mean()\n",
    "\n",
    "def lovasz_softmax(preds, targets):\n",
    "    \"\"\"\n",
    "    Implémentation du Lovász-Softmax pour optimiser directement l'IoU.\n",
    "    Cette perte est particulièrement efficace pour la segmentation.\n",
    "    \n",
    "    Basé sur l'article: \"The Lovász-Softmax loss: A tractable surrogate for the optimization \n",
    "    of the intersection-over-union measure in neural networks\"\n",
    "    \n",
    "    Implémentation simplifiée pour illustration - voir PyTorch-Lovasz pour une \n",
    "    implémentation complète et optimisée.\n",
    "    \"\"\"\n",
    "    preds_soft = torch.softmax(preds, dim=1)\n",
    "    targets_cls = targets.squeeze(1).long()\n",
    "    \n",
    "    lovasz_loss = 0.0\n",
    "    \n",
    "    for c in range(preds.shape[1]):\n",
    "        # Vérifier s'il y a au moins un pixel de cette classe\n",
    "        if (targets_cls == c).sum() == 0:\n",
    "            continue\n",
    "            \n",
    "        # Convertir en one-hot pour la classe actuelle\n",
    "        targets_c = (targets_cls == c).float()\n",
    "        preds_c = preds_soft[:, c]\n",
    "        \n",
    "        # Calcul de l'erreur pour chaque pixel\n",
    "        errors = (targets_c - preds_c).abs()\n",
    "        \n",
    "        # Triez les erreurs par ordre décroissant\n",
    "        sorted_errors, sorted_indices = torch.sort(errors.reshape(-1), descending=True)\n",
    "        \n",
    "        # Conversion des cibles triées\n",
    "        sorted_targets = targets_c.reshape(-1)[sorted_indices]\n",
    "        \n",
    "        # Calculer les incréments d'IoU\n",
    "        intersection = sorted_targets.cumsum(0)\n",
    "        union = sorted_targets.sum() + (1.0 - sorted_targets).cumsum(0)\n",
    "        iou = 1.0 - intersection / (union + 1e-6)\n",
    "        \n",
    "        # Lovász extension\n",
    "        lovasz_grad = torch.zeros_like(iou)\n",
    "        lovasz_grad[:-1] = iou[1:] - iou[:-1]\n",
    "        lovasz_grad[-1] = iou[-1]\n",
    "        \n",
    "        # Calculer la perte pour cette classe\n",
    "        lovasz_loss += (lovasz_grad * sorted_errors).sum()\n",
    "    \n",
    "    return lovasz_loss / preds.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class PostProcessingNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3, base_filters=16):\n",
    "        super(PostProcessingNet, self).__init__()\n",
    "\n",
    "        self.enc1 = self._conv_block(in_channels, base_filters)\n",
    "        self.enc2 = self._conv_block(base_filters, base_filters * 2)\n",
    "        self.enc3 = self._conv_block(base_filters * 2, base_filters * 4)\n",
    "\n",
    "        self.bridge = self._conv_block(base_filters * 4, base_filters * 8)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(base_filters * 8, base_filters * 4, kernel_size=2, stride=2)\n",
    "        self.dec1 = self._conv_block(base_filters * 8, base_filters * 4)\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(base_filters * 4, base_filters * 2, kernel_size=2, stride=2)\n",
    "        self.dec2 = self._conv_block(base_filters * 4, base_filters * 2)\n",
    "        \n",
    "        self.up3 = nn.ConvTranspose2d(base_filters * 2, base_filters, kernel_size=2, stride=2)\n",
    "        self.dec3 = self._conv_block(base_filters * 2, base_filters)\n",
    "\n",
    "        self.final = nn.Conv2d(base_filters, out_channels, kernel_size=1)\n",
    "\n",
    "    def _conv_block(self, in_c, out_c):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.enc1(x)\n",
    "        x = F.max_pool2d(enc1, kernel_size=2, stride=2)\n",
    "        enc2 = self.enc2(x)\n",
    "        x = F.max_pool2d(enc2, kernel_size=2, stride=2)\n",
    "        enc3 = self.enc3(x)\n",
    "        x = F.max_pool2d(enc3, kernel_size=2, stride=2)\n",
    "\n",
    "        x = self.bridge(x)\n",
    "\n",
    "        x = self.up1(x)\n",
    "        x = F.pad(x, [0, enc3.size(3) - x.size(3), 0, enc3.size(2) - x.size(2)])\n",
    "        x = torch.cat([x, enc3], dim=1)\n",
    "        x = self.dec1(x)\n",
    "\n",
    "        x = self.up2(x)\n",
    "        x = F.pad(x, [0, enc2.size(3) - x.size(3), 0, enc2.size(2) - x.size(2)])\n",
    "        x = torch.cat([x, enc2], dim=1)\n",
    "        x = self.dec2(x)\n",
    "\n",
    "        x = self.up3(x)\n",
    "        x = F.pad(x, [0, enc1.size(3) - x.size(3), 0, enc1.size(2) - x.size(2)])\n",
    "        x = torch.cat([x, enc1], dim=1)\n",
    "        x = self.dec3(x)\n",
    "\n",
    "        x = self.final(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_memory_efficient(model, model_post_pro, train_loader, val_loader, optimizer, scheduler, \n",
    "                        criterion, num_epochs=50, checkpoint_path=\"best_post_pro_model_tho.pth\", \n",
    "                        device=\"cuda\", batch_size=None, val_frequency=5):\n",
    "    best_iou = 0.0\n",
    "    best_loss = 2\n",
    "\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"val_iou\": []}\n",
    "    \n",
    "    if batch_size is not None and batch_size < train_loader.batch_size:\n",
    "        print(f\"Attention: Réduction de la taille de batch de {train_loader.batch_size} à {batch_size}\")\n",
    "    for epoch in range(num_epochs):\n",
    "        model_post_pro.train()\n",
    "        total_loss = 0.0\n",
    "        batch_count = 0\n",
    "        \n",
    "        loop = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\", leave=False)\n",
    "        \n",
    "        for batch in loop:\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            images, masks, resized = batch[\"image\"], batch[\"label\"], batch[\"resized\"]\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                initial_outputs = model(images)\n",
    "                probabilities = torch.softmax(initial_outputs, dim=1) \n",
    "                del initial_outputs\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            post_pro_outputs = model_post_pro(probabilities)\n",
    "            \n",
    "            del probabilities\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache() \n",
    "     \n",
    "            \n",
    "            loss = focal_dice_loss(post_pro_outputs, masks) + 0.5 * boundary_loss(post_pro_outputs, masks)            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            batch_loss = loss.item()\n",
    "            del post_pro_outputs, loss, masks\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            total_loss += batch_loss\n",
    "            batch_count += 1\n",
    "            loop.set_postfix(loss=batch_loss)\n",
    "        \n",
    "        avg_train_loss = total_loss / batch_count\n",
    "        history[\"train_loss\"].append(avg_train_loss)\n",
    "        \n",
    "        if epoch % val_frequency == 0 or epoch == num_epochs - 1 or avg_train_loss<best_loss:\n",
    "            if avg_train_loss<best_loss:\n",
    "                best_loss = avg_train_loss\n",
    "            val_loss, val_iou,_ = validate_memory_efficient(\n",
    "                model, model_post_pro, val_loader, criterion, device\n",
    "            )\n",
    "            history[\"val_loss\"].append(val_loss)\n",
    "            history[\"val_iou\"].append(val_iou)\n",
    "            \n",
    "            if scheduler:\n",
    "                scheduler.step(val_loss)\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}, Val IoU: {val_iou:.4f}\")\n",
    "            if val_iou > best_iou:\n",
    "                best_iou = val_iou\n",
    "                torch.save(model_post_pro.state_dict(), checkpoint_path)\n",
    "                print(f\"Meilleur modèle de post-processing sauvegardé avec IoU: {best_iou:.4f}\")\n",
    "        else:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f} (pas de validation)\")\n",
    "            history[\"val_loss\"].append(None)\n",
    "            history[\"val_iou\"].append(None)\n",
    "            \n",
    "            if scheduler and isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                pass\n",
    "            elif scheduler:\n",
    "                scheduler.step()\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return history\n",
    "\n",
    "def validate_memory_efficient(model, model_post_pro, val_loader, criterion, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    model_post_pro.eval()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    all_post_pro_outputs = []\n",
    "    all_initial_outputs = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            images, masks, _ = batch[\"image\"], batch[\"label\"], batch[\"resized\"]\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            \n",
    "            initial_outputs = model(images)\n",
    "            \n",
    "            all_initial_outputs.append(initial_outputs.cpu())\n",
    "            \n",
    "            probabilities = torch.softmax(initial_outputs, dim=1)  \n",
    "            \n",
    "            \n",
    "            del initial_outputs\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            post_pro_outputs = model_post_pro(probabilities)\n",
    "            \n",
    "            all_post_pro_outputs.append(post_pro_outputs.cpu())\n",
    "            \n",
    "            del probabilities\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            if masks.shape[1] == 1:\n",
    "                target_masks = masks.squeeze(1)\n",
    "            else:\n",
    "                target_masks = masks\n",
    "                \n",
    "            loss = focal_dice_loss(post_pro_outputs, masks) + 0.5 * boundary_loss(post_pro_outputs, masks)            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            all_targets.append(masks.cpu())\n",
    "            \n",
    "            del post_pro_outputs, loss, target_masks\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    all_post_pro_outputs = torch.cat(all_post_pro_outputs, dim=0)\n",
    "    all_initial_outputs = torch.cat(all_initial_outputs, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "    \n",
    "    initial_iou, initial_class_ious = compute_multiclass_iou(all_initial_outputs, all_targets, num_classes=3)\n",
    "    post_pro_iou, post_pro_class_ious = compute_multiclass_iou(all_post_pro_outputs, all_targets, num_classes=3)\n",
    "    \n",
    "    print(f\"IoU du modèle initial: {initial_iou:.4f}\")\n",
    "    for cls, iou in enumerate(initial_class_ious):\n",
    "        print(f\"  - Classe {cls}: {iou:.4f}\")\n",
    "    \n",
    "    print(f\"IoU après post-processing: {post_pro_iou:.4f}\")\n",
    "    for cls, iou in enumerate(post_pro_class_ious):\n",
    "        print(f\"  - Classe {cls}: {iou:.4f}\")\n",
    "    \n",
    "    print(f\"Différence d'IoU globale: {post_pro_iou - initial_iou:.4f} ({(post_pro_iou - initial_iou) / initial_iou * 100:.2f}%)\")\n",
    "    \n",
    "    for cls in range(len(initial_class_ious)):\n",
    "        diff = post_pro_class_ious[cls] - initial_class_ious[cls]\n",
    "        percent = (diff / initial_class_ious[cls] * 100) if initial_class_ious[cls] > 0 else float('inf')\n",
    "        print(f\"  - Classe {cls}: {diff:.4f} ({percent:.2f}%)\")\n",
    "    \n",
    "    del all_post_pro_outputs, all_initial_outputs, all_targets\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    val_loss = total_loss / len(val_loader)\n",
    "    return val_loss, post_pro_iou, initial_iou \n",
    "\n",
    "def visualize_memory_efficient(model, model_post_pro, val_loader, num_samples=2, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    model_post_pro.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 4, figsize=(20, 5*num_samples))\n",
    "    samples_seen = 0\n",
    "    all_post_pro_outputs = []\n",
    "    all_initial_outputs = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            if samples_seen >= num_samples:\n",
    "                break\n",
    "                \n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            images, masks, _ = batch[\"image\"], batch[\"label\"], batch[\"resized\"]\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            \n",
    "            initial_outputs = model(images)\n",
    "            \n",
    "            probabilities = torch.softmax(initial_outputs, dim=1) \n",
    "            initial_masks = torch.argmax(initial_outputs, dim=1).cpu()\n",
    "            all_initial_outputs.append(initial_masks)\n",
    "            initial_masks = initial_masks.numpy()\n",
    "\n",
    "            del initial_outputs\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            post_pro_outputs = model_post_pro(probabilities)\n",
    "            post_pro_masks = torch.argmax(post_pro_outputs, dim=1).cpu()\n",
    "            all_post_pro_outputs.append(post_pro_masks)\n",
    "            post_pro_masks =post_pro_masks.numpy()\n",
    "            \n",
    "            del probabilities, post_pro_outputs\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            if masks.shape[1] == 1:\n",
    "                target_masks = masks.squeeze(1).cpu()\n",
    "            else:\n",
    "                target_masks = torch.argmax(masks, dim=1).cpu()\n",
    "            all_targets.append(target_masks)\n",
    "            target_masks = target_masks.numpy()\n",
    "            \n",
    "            if samples_seen < num_samples:\n",
    "                axes[samples_seen, 0].imshow(images[i, 0].cpu().numpy(), cmap='gray')\n",
    "                axes[samples_seen, 0].set_title('Image originale')\n",
    "                axes[samples_seen, 0].axis('off')\n",
    "                \n",
    "                axes[samples_seen, 1].imshow(initial_masks[i], cmap='jet')\n",
    "                axes[samples_seen, 1].set_title('Prédiction initiale')\n",
    "                axes[samples_seen, 1].axis('off')\n",
    "                \n",
    "                axes[samples_seen, 2].imshow(post_pro_masks[i], cmap='jet')\n",
    "                axes[samples_seen, 2].set_title('Post-traité')\n",
    "                axes[samples_seen, 2].axis('off')\n",
    "                \n",
    "                axes[samples_seen, 3].imshow(target_masks[i], cmap='jet')\n",
    "                axes[samples_seen, 3].set_title('Ground Truth')\n",
    "                axes[samples_seen, 3].axis('off')\n",
    "                \n",
    "                samples_seen += 1\n",
    "            \n",
    "            del images, masks, initial_masks, post_pro_masks, target_masks\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "    all_post_pro_outputs = torch.cat(all_post_pro_outputs, dim=0)\n",
    "    all_initial_outputs = torch.cat(all_initial_outputs, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "    initial_ious = []\n",
    "    post_pro_ious = []\n",
    "\n",
    "    for i in range(all_targets.shape[0]):\n",
    "        initial_iou, _ = compute_multiclass_iou(all_initial_outputs[i].unsqueeze(0), all_targets[i].unsqueeze(0), num_classes=3)\n",
    "        post_pro_iou, _ = compute_multiclass_iou(all_post_pro_outputs[i].unsqueeze(0), all_targets[i].unsqueeze(0), num_classes=3)\n",
    "        \n",
    "        initial_ious.append(initial_iou)\n",
    "        post_pro_ious.append(post_pro_iou)\n",
    "\n",
    "def main():\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    torch.backends.cudnn.benchmark = False  \n",
    "    torch.backends.cudnn.deterministic = True \n",
    "    model = smp.Unet(\n",
    "        encoder_name=\"resnet34\",       \n",
    "        encoder_weights=None,          \n",
    "        in_channels=1,                 \n",
    "        classes=3                      \n",
    "    ).to(device)\n",
    "\n",
    "    checkpoint_path = \"best_model_0_682/best_model.pth\"\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    model.eval()\n",
    "    print(\" Modèle chargé avec succès !\")\n",
    "\n",
    "    model_post_pro = PostProcessingNet(in_channels=3, out_channels=3, base_filters=32).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model_post_pro.parameters(), lr=0.0005)  # LR réduit\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    history = train_memory_efficient(\n",
    "        model, model_post_pro, train_loader, val_loader, \n",
    "        optimizer, scheduler, criterion, num_epochs=30,\n",
    "        val_frequency=5, checkpoint_path=\"best_post_pro_model_tho_li_2.pth\"\n",
    "    )\n",
    "    \n",
    "    model_post_pro.load_state_dict(torch.load(\"best_post_pro_model_tho_li_2.pth\"))\n",
    "    \n",
    "    fig = visualize_memory_efficient(model, model_post_pro, val_loader, num_samples=2)\n",
    "    \n",
    "    return model_post_pro, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_post_pro, history = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_post_pro = PostProcessingNet(in_channels=3, out_channels=3, base_filters=32).to(device)\n",
    "model_post_pro.load_state_dict(torch.load(\"best_model_0_682/best_post_pro_model_tho_li_2.pth\"))\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",       \n",
    "    encoder_weights=None,          \n",
    "    in_channels=1,                 \n",
    "    classes=3                      \n",
    ").to(device)\n",
    "\n",
    "checkpoint_path = \"best_model_0_682/best_model.pth\"\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "fig = visualize_memory_efficient(model, model_post_pro, val_loader, num_samples=9)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV - Post-processing manuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.ndimage import label, generate_binary_structure\n",
    "\n",
    "def pipeline_modifie(pred_mask, batch_idx=0, i=0):\n",
    "    is_tensor = isinstance(pred_mask, torch.Tensor)\n",
    "    original_device = None\n",
    "    \n",
    "    if is_tensor:\n",
    "        original_device = pred_mask.device\n",
    "        pred_mask_np = pred_mask.cpu().numpy()\n",
    "    else:\n",
    "        pred_mask_np = pred_mask\n",
    "    \n",
    "    input_had_channel_dim = False\n",
    "    if pred_mask_np.ndim == 3 and pred_mask_np.shape[0] == 1:\n",
    "        input_had_channel_dim = True\n",
    "        pred_mask_np = pred_mask_np.squeeze(0)\n",
    "    \n",
    "    result_mask = pred_mask_np.copy()\n",
    "    \n",
    "    class2_mask = np.zeros_like(pred_mask_np, dtype=np.uint8)\n",
    "    class2_mask[pred_mask_np == 2] = 1\n",
    "    \n",
    "    structure = generate_binary_structure(2, 2)\n",
    "    labeled, num_features = label(class2_mask, structure=structure)\n",
    "    \n",
    "    if num_features == 0:\n",
    "        if is_tensor:\n",
    "            if input_had_channel_dim:\n",
    "                result_mask = np.expand_dims(result_mask, 0)\n",
    "            result_mask = torch.from_numpy(result_mask).to(original_device)\n",
    "        return result_mask\n",
    "    \n",
    "    component_sizes = np.bincount(labeled.ravel())[1:]\n",
    "    \n",
    "    largest_comp_idx = np.argmax(component_sizes) + 1\n",
    "    \n",
    "    class2_processed = np.zeros_like(pred_mask_np, dtype=np.uint8)\n",
    "    class2_processed[labeled == largest_comp_idx] = 2\n",
    "    \n",
    "    result_mask = np.where(pred_mask_np == 1, 1, 0)  \n",
    "    result_mask = np.where(class2_processed == 2, 2, result_mask)  \n",
    "    \n",
    "    if is_tensor:\n",
    "        if input_had_channel_dim:\n",
    "            result_mask = np.expand_dims(result_mask, 0)\n",
    "        result_mask = torch.from_numpy(result_mask).to(original_device)\n",
    "    \n",
    "    return result_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  \n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "def compute_multiclass_iou_numpy(preds, targets, num_classes=3):\n",
    "    if len(preds.shape) == 2:\n",
    "        preds_cls = preds\n",
    "    else:\n",
    "        if len(preds.shape) == 3 and preds.shape[0] > 1:\n",
    "            preds_cls = np.argmax(preds, axis=0)\n",
    "        else:\n",
    "            preds_cls = preds.squeeze()  \n",
    "    \n",
    "    targets = targets.squeeze()\n",
    "    \n",
    "    class_ious = []\n",
    "    \n",
    "    for cls in range(num_classes):\n",
    "        pred_mask = (preds_cls == cls).astype(np.float32)\n",
    "        target_mask = (targets == cls).astype(np.float32)\n",
    "        \n",
    "        intersection = (pred_mask * target_mask).sum()\n",
    "        union = ((pred_mask + target_mask) > 0).astype(np.float32).sum()\n",
    "        \n",
    "        iou = intersection / (union + 1e-6)\n",
    "        class_ious.append(iou)\n",
    "    \n",
    "    mean_iou = sum(class_ious) / num_classes\n",
    "    return class_ious[1]\n",
    "\n",
    "def test_post_processing_random(model,post_pro_model, val_loader, output_dir=\"post_processing_results\", \n",
    "                               num_batches=10, samples_per_batch=20):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    all_batches = list(val_loader)\n",
    "    \n",
    "    if num_batches > len(all_batches):\n",
    "        num_batches = len(all_batches)\n",
    "        print(f\"Warning: Requested {num_batches} batches but only {len(all_batches)} available.\")\n",
    "    \n",
    "    selected_batches = random.sample(all_batches, num_batches)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(all_batches):\n",
    "            images, masks = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
    "\n",
    "            \n",
    "            initial_outputs = model(images)\n",
    "            initial_preds = torch.argmax(initial_outputs, dim=1).cpu().numpy()\n",
    "\n",
    "            probabilities = torch.softmax(initial_outputs, dim=1) \n",
    "\n",
    "            preds = post_pro_model(probabilities)\n",
    "            pred_indices = torch.argmax(preds, dim=1)\n",
    "            \n",
    "            batch_size = images.size(0)\n",
    "\n",
    "            \n",
    "            print(f\"\\nTraitement du batch {batch_idx+1}/{len(all_batches)}\")\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                pred_mask = (pred_indices[i] == 1).cpu().numpy().squeeze()\n",
    "                true_mask = (masks[i] == 1).cpu().numpy().squeeze()\n",
    "                post_processed_mask = pipeline_modifie(\n",
    "                    pred_mask,batch_idx ,i               )\n",
    "                \n",
    "                iou_before = compute_multiclass_iou_numpy(pred_mask, true_mask, num_classes=3)\n",
    "                iou_after = compute_multiclass_iou_numpy(post_processed_mask, true_mask, num_classes=3)\n",
    "                \n",
    "                img = images[i].cpu().numpy()\n",
    "                \n",
    "                if len(img.shape) == 3 and img.shape[0] in [1, 3]:  # Format CHW\n",
    "                    img = img.transpose(1, 2, 0)\n",
    "                \n",
    "                if len(img.shape) == 3 and img.shape[2] == 3:  \n",
    "                    \n",
    "                    img = (img - img.min()) / (img.max() - img.min() + 1e-6)\n",
    "                elif len(img.shape) == 3 and img.shape[2] == 1:  \n",
    "                    img = img.squeeze()\n",
    "                results.append({\n",
    "                    'batch': batch_idx,\n",
    "                    'sample': i,\n",
    "                    'iou_before': iou_before,\n",
    "                    'iou_after': iou_after,\n",
    "                    'improvement': iou_after - iou_before,\n",
    "                    'true_mask' : true_mask,\n",
    "                    'initial_pred_mask' : pred_mask,\n",
    "                    'post_processed_mask' :post_processed_mask,\n",
    "                    'img' : img\n",
    "                })\n",
    "                \n",
    "                \n",
    "    print(\"\\n----- RÉSUMÉ DES RÉSULTATS -----\")\n",
    "    avg_improvement = sum(r['improvement'] for r in results) / len(results) if results else 0\n",
    "    print(f\"Amélioration moyenne de l'IoU: {avg_improvement:.4f}\")\n",
    "    \n",
    "    if results:\n",
    "        results.sort(key=lambda x: x['improvement'], reverse=True)\n",
    "        print(f\"Meilleure amélioration: {results[0]['improvement']:.4f} (batch {results[0]['batch']}, échantillon {results[0]['sample']})\")\n",
    "        print(f\"Pire amélioration: {results[-1]['improvement']:.4f} (batch {results[-1]['batch']}, échantillon {results[-1]['sample']})\")\n",
    "        plt.figure(figsize=(16, 4))\n",
    "        \n",
    "        plt.subplot(1, 4, 1)\n",
    "        plt.imshow(results[0]['img'], cmap=\"gray\" if len(img.shape) == 2 else None)\n",
    "        plt.title(\"Image d'entrée\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        plt.subplot(1, 4, 2)\n",
    "        plt.imshow(results[0]['true_mask'], cmap=\"jet\")\n",
    "        plt.title(\"Masque réel (Ground Truth)\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        plt.subplot(1, 4, 3)\n",
    "        plt.imshow(results[0]['initial_pred_mask'], cmap=\"jet\")\n",
    "        plt.title(f\"Masque prédit - IoU: {iou_before:.4f}\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        plt.subplot(1, 4, 4)\n",
    "        plt.imshow(results[0]['post_processed_mask'], cmap=\"jet\")\n",
    "        plt.title(f\"Post-traité - IoU: {iou_after:.4f}\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        filename = f\"{output_dir}/batch{results[0]['batch']}_sample{results[0]['sample']}_best.png\"\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "        print(f\"Image sauvegardée: {filename}\")\n",
    "        plt.figure(figsize=(16, 4))\n",
    "        \n",
    "        plt.subplot(1, 4, 1)\n",
    "        plt.imshow(results[-1]['img'], cmap=\"gray\" if len(img.shape) == 2 else None)\n",
    "        plt.title(\"Image d'entrée\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        plt.subplot(1, 4, 2)\n",
    "        plt.imshow(results[-1]['true_mask'], cmap=\"jet\")\n",
    "        plt.title(\"Masque réel (Ground Truth)\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        plt.subplot(1, 4, 3)\n",
    "        plt.imshow(results[-1]['initial_pred_mask'], cmap=\"jet\")\n",
    "        plt.title(f\"Masque prédit - IoU: {iou_before:.4f}\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        plt.subplot(1, 4, 4)\n",
    "        plt.imshow(results[-1]['post_processed_mask'], cmap=\"jet\")\n",
    "        plt.title(f\"Post-traité - IoU: {iou_after:.4f}\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        # Sauvegarder l'image\n",
    "        filename = f\"{output_dir}/batch{results[-1]['batch']}_sample{results[-1]['sample']}_worst.png\"\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "        print(f\"Image sauvegardée: {filename}\")\n",
    "    \n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_post_pro = PostProcessingNet(in_channels=3, out_channels=3, base_filters=32).to(device)\n",
    "model_post_pro.load_state_dict(torch.load(\"best_post_pro_model_tho_li_2.pth\"))\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",       \n",
    "    encoder_weights=None,          \n",
    "    in_channels=1,                 \n",
    "    classes=3                      \n",
    ").to(device)\n",
    "\n",
    "checkpoint_path = \"best_model.pth\"\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_post_processing_random(model,model_post_pro,val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V - Test et mise en forme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.ndimage import label\n",
    "\n",
    "resize_transform = T.Resize((160, 272), interpolation=T.InterpolationMode.NEAREST)\n",
    "\n",
    "def morphological_postprocessing(mask):\n",
    "  \n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    \n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def postprocess_predictions(preds, resized, file_names):\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for i in range(preds.shape[0]):  \n",
    "        pred = torch.argmax(preds[i], dim=0, keepdim=True) \n",
    "        \n",
    "        if resized[i]:  \n",
    "            pred = resize_transform(pred.unsqueeze(0)).squeeze(0) \n",
    "        pred = pipeline_modifie(pred)\n",
    "\n",
    "        pred_np = pred.cpu().numpy().astype(np.uint8)\n",
    "\n",
    "        pred_np = morphological_postprocessing(pred_np)\n",
    "        processed_pred = pred_np.flatten()\n",
    "\n",
    "        if not resized[i]:\n",
    "            pad_size = (160 * 272) - processed_pred.shape[0] \n",
    "            processed_pred = F.pad(torch.tensor(processed_pred), (0, pad_size), value=-1).numpy()\n",
    "\n",
    "        results[file_names[i]] = processed_pred\n",
    "\n",
    "    df = pd.DataFrame.from_dict(results, orient=\"index\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class TestImageDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.files = [f for f in os.listdir(root_dir) if f.endswith(\".npy\")]\n",
    "\n",
    "        self.resize_transform = transforms.Resize((160, 160), interpolation=transforms.InterpolationMode.BILINEAR)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.files[idx]\n",
    "        file_path = os.path.join(self.root_dir, file_name)\n",
    "\n",
    "        image = np.load(file_path).astype(np.float32)\n",
    "        original_size = image.shape\n",
    "        resized = False  \n",
    "\n",
    "        image_min, image_max = image.min(), image.max()\n",
    "        if image_max > image_min:  \n",
    "            image = (image - image_min) / (image_max - image_min)\n",
    "        else:\n",
    "            image = np.zeros_like(image)  \n",
    "\n",
    "        image = torch.tensor(image, dtype=torch.float32).unsqueeze(0)  \n",
    "        if original_size != (160, 160):\n",
    "            image = self.resize_transform(image)\n",
    "            resized = True  \n",
    "\n",
    "        return {\n",
    "            \"image\": image,\n",
    "            \"resized\": resized,\n",
    "            \"file_name\": os.path.splitext(file_name)[0] \n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm  \n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Utilisation de : {device}\")\n",
    "\n",
    "#\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",       \n",
    "    encoder_weights=None,          \n",
    "    in_channels=1,                 \n",
    "    classes=3                      \n",
    ").to(device)\n",
    "\n",
    "checkpoint_path = \"best_model.pth\"\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "\n",
    "model_post_pro = PostProcessingNet(in_channels=3, out_channels=3, base_filters=32).to(device)\n",
    "model_post_pro.load_state_dict(torch.load(\"best_post_pro_model_tho_li_2.pth\"))\n",
    "\n",
    "\n",
    "print(\" Modèle chargé avec succès !\")\n",
    "\n",
    "test_dataset = TestImageDataset(root_dir=\"images test\")  $\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=8,  \n",
    "    shuffle=False,\n",
    "    pin_memory=True,  \n",
    "    num_workers=4  \n",
    ")\n",
    "\n",
    "model.eval()\n",
    "all_results = pd.DataFrame()  \n",
    "\n",
    "with torch.no_grad():\n",
    "    loop = tqdm(test_loader, desc=\"Traitement des images de test\", unit=\"image\")\n",
    "    \n",
    "    for batch in loop:\n",
    "        images = batch[\"image\"].to(device, non_blocking=True)  \n",
    "        resized = batch[\"resized\"]  \n",
    "        file_names = batch[\"file_name\"]  \n",
    "                \n",
    "        initial_outputs = model(images)\n",
    "        initial_preds = torch.argmax(initial_outputs, dim=1).cpu().numpy()\n",
    "\n",
    "        probabilities = torch.softmax(initial_outputs, dim=1) \n",
    "\n",
    "        preds = model_post_pro(probabilities)\n",
    "\n",
    "        df_preds = postprocess_predictions(preds, resized, file_names)  # Post-traitement\n",
    "\n",
    "        all_results = pd.concat([all_results, df_preds])\n",
    "\n",
    "        loop.set_postfix(Images_traitees=len(all_results))\n",
    "\n",
    "all_results.to_csv(\"predictions_test.csv\")\n",
    "print(\"Prédictions sauvegardées dans 'predictions_test.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "vis_dir = \"visualizations\"\n",
    "os.makedirs(vis_dir, exist_ok=True)\n",
    "\n",
    "predictions_df = pd.read_csv(\"predictions_test.csv\", index_col=0)\n",
    "\n",
    "num_vis = min(10, len(predictions_df))\n",
    "random_samples = random.sample(list(predictions_df.index), num_vis)\n",
    "\n",
    "print(f\"\\nGénération de {num_vis} visualisations aléatoires...\")\n",
    "\n",
    "for i, file_name in enumerate(random_samples):\n",
    "    img_path = os.path.join(\"images test\", f\"{file_name}.npy\")\n",
    "    orig_image = np.load(img_path).astype(np.float32)\n",
    "    \n",
    "    image_min, image_max = orig_image.min(), orig_image.max()\n",
    "    if image_max > image_min:\n",
    "        orig_image = (orig_image - image_min) / (image_max - image_min)\n",
    "    \n",
    "    prediction = predictions_df.loc[file_name].values\n",
    "    \n",
    "    prediction = prediction.reshape(160, 272).astype(np.uint8)\n",
    "    \n",
    "    colors = [\n",
    "        [0, 0, 0],      \n",
    "        [255, 0, 0],    \n",
    "        [0, 255, 0],    \n",
    "    ]\n",
    "    \n",
    "    pred_colored = np.zeros((prediction.shape[0], prediction.shape[1], 3), dtype=np.uint8)\n",
    "    for class_idx, color in enumerate(colors):\n",
    "        pred_colored[prediction == class_idx] = color\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    axes[0].imshow(orig_image, cmap='gray')\n",
    "    axes[0].set_title(f'Image originale: {file_name}')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(pred_colored)\n",
    "    axes[1].set_title('Segmentation prédite')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    legend_elements = [\n",
    "        plt.Rectangle((0, 0), 1, 1, color=[c/255 for c in colors[0]], label='Classe 0'),\n",
    "        plt.Rectangle((0, 0), 1, 1, color=[c/255 for c in colors[1]], label='Classe 1'),\n",
    "        plt.Rectangle((0, 0), 1, 1, color=[c/255 for c in colors[2]], label='Classe 2')\n",
    "    ]\n",
    "    axes[1].legend(handles=legend_elements, loc='lower right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(vis_dir, f'sample_{i}_{file_name}.png'), dpi=150)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(f\"Visualisation {i+1}/{num_vis} générée\")\n",
    "\n",
    "print(f\"{num_vis} visualisations générées avec succès dans '{vis_dir}'!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mva2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
